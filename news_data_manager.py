#!/usr/bin/env python3
"""
–ú–µ–Ω–µ–¥–∂–µ—Ä –¥–∞–Ω–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –∑–∞ 3 –≥–æ–¥–∞
–°–æ–∑–¥–∞–Ω–∏–µ, —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π
"""

import os
import json
import logging
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
import pickle

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class NewsDataManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –¥–∞–Ω–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –∑–∞ 3 –≥–æ–¥–∞"""
    
    def __init__(self, data_dir: str = "data/news_3year"):
        self.data_dir = data_dir
        self.news_file = os.path.join(data_dir, "news_3year_data.json")
        self.metadata_file = os.path.join(data_dir, "news_metadata.json")
        
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        os.makedirs(data_dir, exist_ok=True)
        
        logger.info(f"‚úÖ –ú–µ–Ω–µ–¥–∂–µ—Ä –Ω–æ–≤–æ—Å—Ç–µ–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω: {data_dir}")
    
    def generate_3year_news(self, symbols: List[str], start_date: datetime, end_date: datetime) -> Dict[str, List[Dict]]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π –∑–∞ 3 –≥–æ–¥–∞ –¥–ª—è –≤—Å–µ—Ö —Å–∏–º–≤–æ–ª–æ–≤"""
        
        logger.info(f"üì∞ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π –∑–∞ 3 –≥–æ–¥–∞ –¥–ª—è {len(symbols)} —Å–∏–º–≤–æ–ª–æ–≤...")
        logger.info(f"üìÖ –ü–µ—Ä–∏–æ–¥: {start_date.date()} - {end_date.date()}")
        
        # –¢–∏–ø—ã –Ω–æ–≤–æ—Å—Ç–µ–π —Å —Ä–∞–∑–Ω—ã–º –≤–ª–∏—è–Ω–∏–µ–º
        news_templates = [
            # –°–∏–ª—å–Ω–æ –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏
            {
                'title_template': '{symbol}: –†–µ–∫–æ—Ä–¥–Ω–∞—è –ø—Ä–∏–±—ã–ª—å –ø—Ä–µ–≤—ã—à–∞–µ—Ç –ø—Ä–æ–≥–Ω–æ–∑—ã –Ω–∞ {percent}%',
                'content_template': '–ö–æ–º–ø–∞–Ω–∏—è {symbol} –ø–æ–∫–∞–∑–∞–ª–∞ –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω–æ –≤—ã—Å–æ–∫—É—é –ø—Ä–∏–±—ã–ª—å, –ø—Ä–µ–≤—ã—Å–∏–≤ –ø—Ä–æ–≥–Ω–æ–∑—ã –∞–Ω–∞–ª–∏—Ç–∏–∫–æ–≤ –Ω–∞ {percent}%.',
                'sentiment_score': 0.9,
                'confidence': 0.95,
                'impact': 'very_high',
                'probability': 0.05
            },
            {
                'title_template': '{symbol}: –ö—Ä—É–ø–Ω—ã–µ –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏ –∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ –±–∏–∑–Ω–µ—Å–∞',
                'content_template': '{symbol} –æ–±—ä—è–≤–∏–ª–∞ –æ –ø–ª–∞–Ω–∞—Ö –∫—Ä—É–ø–Ω—ã—Ö –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–π –≤ —Ä–∞–∑–≤–∏—Ç–∏–µ –Ω–æ–≤—ã—Ö –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–π –Ω–∞ —Å—É–º–º—É {amount} –º–ª—Ä–¥ —Ä—É–±.',
                'sentiment_score': 0.8,
                'confidence': 0.85,
                'impact': 'high',
                'probability': 0.08
            },
            {
                'title_template': '{symbol}: –ü–æ–≤—ã—à–µ–Ω–∏–µ –¥–∏–≤–∏–¥–µ–Ω–¥–æ–≤ –∏ –≤—ã–∫—É–ø –∞–∫—Ü–∏–π',
                'content_template': '–°–æ–≤–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–≤ {symbol} –æ–¥–æ–±—Ä–∏–ª –ø–æ–≤—ã—à–µ–Ω–∏–µ –¥–∏–≤–∏–¥–µ–Ω–¥–Ω—ã—Ö –≤—ã–ø–ª–∞—Ç –Ω–∞ {percent}% –∏ –ø—Ä–æ–≥—Ä–∞–º–º—É –≤—ã–∫—É–ø–∞ –∞–∫—Ü–∏–π.',
                'sentiment_score': 0.7,
                'confidence': 0.8,
                'impact': 'high',
                'probability': 0.1
            },
            # –ü–æ–∑–∏—Ç–∏–≤–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏
            {
                'title_template': '{symbol}: –°—Ç–∞–±–∏–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –∫–≤–∞—Ä—Ç–∞–ª–µ',
                'content_template': '–ö–æ–º–ø–∞–Ω–∏—è {symbol} –ø–æ–∫–∞–∑–∞–ª–∞ —Å—Ç–∞–±–∏–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –ø—Ä–æ–≥–Ω–æ–∑–∞–º –∞–Ω–∞–ª–∏—Ç–∏–∫–æ–≤.',
                'sentiment_score': 0.6,
                'confidence': 0.7,
                'impact': 'medium',
                'probability': 0.15
            },
            {
                'title_template': '{symbol}: –ù–æ–≤—ã–µ –∫–æ–Ω—Ç—Ä–∞–∫—Ç—ã –∏ –ø–∞—Ä—Ç–Ω–µ—Ä—Å—Ç–≤–∞',
                'content_template': '{symbol} –ø–æ–¥–ø–∏—Å–∞–ª–∞ –∫—Ä—É–ø–Ω—ã–µ –∫–æ–Ω—Ç—Ä–∞–∫—Ç—ã, —á—Ç–æ —É–∫—Ä–µ–ø–∏—Ç –ø–æ–∑–∏—Ü–∏–∏ –∫–æ–º–ø–∞–Ω–∏–∏ –Ω–∞ —Ä—ã–Ω–∫–µ.',
                'sentiment_score': 0.5,
                'confidence': 0.6,
                'impact': 'medium',
                'probability': 0.12
            },
            # –ù–µ–≥–∞—Ç–∏–≤–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏
            {
                'title_template': '{symbol}: –°–Ω–∏–∂–µ–Ω–∏–µ –ø—Ä–∏–±—ã–ª–∏ –∏ —É–±—ã—Ç–∫–∏',
                'content_template': '–ö–æ–º–ø–∞–Ω–∏—è {symbol} –ø–æ–∫–∞–∑–∞–ª–∞ —Å–Ω–∏–∂–µ–Ω–∏–µ –ø—Ä–∏–±—ã–ª–∏ –Ω–∞ {percent}% –∏–∑-–∑–∞ –Ω–µ–±–ª–∞–≥–æ–ø—Ä–∏—è—Ç–Ω—ã—Ö —É—Å–ª–æ–≤–∏–π –Ω–∞ —Ä—ã–Ω–∫–µ.',
                'sentiment_score': -0.7,
                'confidence': 0.8,
                'impact': 'high',
                'probability': 0.08
            },
            {
                'title_template': '{symbol}: –†–µ–≥—É–ª—è—Ç–æ—Ä–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –∏ —à—Ç—Ä–∞—Ñ—ã',
                'content_template': '–ù–∞ {symbol} –Ω–∞–ª–æ–∂–µ–Ω—ã —à—Ç—Ä–∞—Ñ—ã —Ä–µ–≥—É–ª—è—Ç–æ—Ä–æ–º –∑–∞ –Ω–∞—Ä—É—à–µ–Ω–∏—è –≤ –æ—Ç—á–µ—Ç–Ω–æ—Å—Ç–∏ –Ω–∞ —Å—É–º–º—É {amount} –º–ª–Ω —Ä—É–±.',
                'sentiment_score': -0.8,
                'confidence': 0.85,
                'impact': 'high',
                'probability': 0.05
            },
            {
                'title_template': '{symbol}: –°–Ω–∏–∂–µ–Ω–∏–µ —Ä–µ–π—Ç–∏–Ω–≥–∞ –∞–Ω–∞–ª–∏—Ç–∏–∫–∞–º–∏',
                'content_template': '–í–µ–¥—É—â–∏–µ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –ø–æ–Ω–∏–∑–∏–ª–∏ —Ä–µ–π—Ç–∏–Ω–≥ {symbol} —Å "–ø–æ–∫—É–ø–∞—Ç—å" –¥–æ "–¥–µ—Ä–∂–∞—Ç—å" –∏–∑-–∑–∞ —É—Ö—É–¥—à–µ–Ω–∏—è –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤.',
                'sentiment_score': -0.6,
                'confidence': 0.7,
                'impact': 'medium',
                'probability': 0.1
            },
            # –ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏
            {
                'title_template': '{symbol}: –û–±—ã—á–Ω—ã–µ —Ç–æ—Ä–≥–æ–≤—ã–µ —Å–µ—Å—Å–∏–∏',
                'content_template': '–¢–æ—Ä–≥–∏ {symbol} –ø—Ä–æ—à–ª–∏ –≤ –æ–±—ã—á–Ω–æ–º —Ä–µ–∂–∏–º–µ –±–µ–∑ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π.',
                'sentiment_score': 0.1,
                'confidence': 0.4,
                'impact': 'low',
                'probability': 0.2
            },
            {
                'title_template': '{symbol}: –ü–ª–∞–Ω–æ–≤—ã–µ –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è',
                'content_template': '–ö–æ–º–ø–∞–Ω–∏—è {symbol} –ø—Ä–æ–≤–µ–ª–∞ –ø–ª–∞–Ω–æ–≤–æ–µ —Å–æ–±—Ä–∞–Ω–∏–µ –∞–∫—Ü–∏–æ–Ω–µ—Ä–æ–≤.',
                'sentiment_score': 0.0,
                'confidence': 0.3,
                'impact': 'low',
                'probability': 0.07
            }
        ]
        
        all_news = {}
        
        for symbol in symbols:
            logger.info(f"  üìä –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è {symbol}...")
            symbol_news = []
            current_date = start_date
            
            while current_date <= end_date:
                # –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –Ω–æ–≤–æ—Å—Ç–∏ –≤ –¥–µ–Ω—å
                news_probability = 0.6  # 60% –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –Ω–æ–≤–æ—Å—Ç–∏ –≤ –¥–µ–Ω—å
                
                if np.random.random() < news_probability:
                    # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–æ–≤–æ—Å—Ç–µ–π –≤ –¥–µ–Ω—å (1-3)
                    num_news = np.random.choice([1, 2, 3], p=[0.6, 0.3, 0.1])
                    
                    for _ in range(num_news):
                        # –í—ã–±–∏—Ä–∞–µ–º —à–∞–±–ª–æ–Ω –Ω–æ–≤–æ—Å—Ç–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
                        template = np.random.choice(news_templates, p=[t['probability'] for t in news_templates])
                        
                        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —à–∞–±–ª–æ–Ω–∞
                        params = {
                            'symbol': symbol,
                            'percent': np.random.randint(5, 25),
                            'amount': np.random.randint(1, 10)
                        }
                        
                        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤–æ—Å—Ç—å
                        news_item = {
                            'title': template['title_template'].format(**params),
                            'content': template['content_template'].format(**params),
                            'published_at': current_date + timedelta(hours=np.random.randint(9, 18)),
                            'source': 'Financial News',
                            'symbol': symbol,
                            'sentiment_score': template['sentiment_score'],
                            'confidence': template['confidence'],
                            'impact': template['impact'],
                            'category': self._categorize_news(template['sentiment_score']),
                            'id': f"{symbol}_{current_date.strftime('%Y%m%d')}_{len(symbol_news)}"
                        }
                        
                        symbol_news.append(news_item)
                
                current_date += timedelta(days=1)
            
            all_news[symbol] = symbol_news
            logger.info(f"    ‚úÖ {symbol}: {len(symbol_news)} –Ω–æ–≤–æ—Å—Ç–µ–π")
        
        logger.info(f"üì∞ –í—Å–µ–≥–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ –Ω–æ–≤–æ—Å—Ç–µ–π: {sum(len(news) for news in all_news.values())}")
        return all_news
    
    def _categorize_news(self, sentiment_score: float) -> str:
        """–ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π –ø–æ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—é"""
        if sentiment_score > 0.5:
            return 'very_positive'
        elif sentiment_score > 0.2:
            return 'positive'
        elif sentiment_score > -0.2:
            return 'neutral'
        elif sentiment_score > -0.5:
            return 'negative'
        else:
            return 'very_negative'
    
    def save_news_data(self, news_data: Dict[str, List[Dict]], metadata: Dict[str, Any] = None):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π"""
        
        logger.info(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –≤ {self.news_file}...")
        
        try:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º datetime –æ–±—ä–µ–∫—Ç—ã –≤ —Å—Ç—Ä–æ–∫–∏
            def convert_datetime(obj):
                if isinstance(obj, datetime):
                    return obj.isoformat()
                elif isinstance(obj, dict):
                    return {k: convert_datetime(v) for k, v in obj.items()}
                elif isinstance(obj, list):
                    return [convert_datetime(item) for item in obj]
                else:
                    return obj
            
            converted_data = convert_datetime(news_data)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            with open(self.news_file, 'w', encoding='utf-8') as f:
                json.dump(converted_data, f, ensure_ascii=False, indent=2)
            
            # –°–æ–∑–¥–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            if metadata is None:
                metadata = {
                    'created_at': datetime.now().isoformat(),
                    'total_symbols': len(news_data),
                    'total_news': sum(len(news) for news in news_data.values()),
                    'symbols': list(news_data.keys()),
                    'date_range': {
                        'start': min(min(news['published_at'] for news in news_list) for news_list in news_data.values()).isoformat(),
                        'end': max(max(news['published_at'] for news in news_list) for news_list in news_data.values()).isoformat()
                    }
                }
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            with open(self.metadata_file, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)
            
            logger.info(f"‚úÖ –î–∞–Ω–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–µ–π —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã:")
            logger.info(f"  üìÅ –§–∞–π–ª: {self.news_file}")
            logger.info(f"  üìä –°–∏–º–≤–æ–ª–æ–≤: {metadata['total_symbols']}")
            logger.info(f"  üì∞ –ù–æ–≤–æ—Å—Ç–µ–π: {metadata['total_news']}")
            logger.info(f"  üìÖ –ü–µ—Ä–∏–æ–¥: {metadata['date_range']['start']} - {metadata['date_range']['end']}")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π: {e}")
    
    def load_news_data(self) -> Optional[Dict[str, List[Dict]]]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π"""
        
        if not os.path.exists(self.news_file):
            logger.warning(f"‚ö†Ô∏è –§–∞–π–ª –Ω–æ–≤–æ—Å—Ç–µ–π –Ω–µ –Ω–∞–π–¥–µ–Ω: {self.news_file}")
            return None
        
        try:
            logger.info(f"üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –∏–∑ {self.news_file}...")
            
            with open(self.news_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Å—Ç—Ä–æ–∫–∏ –æ–±—Ä–∞—Ç–Ω–æ –≤ datetime
            def convert_string_to_datetime(obj):
                if isinstance(obj, str) and 'T' in obj:
                    try:
                        return datetime.fromisoformat(obj)
                    except:
                        return obj
                elif isinstance(obj, dict):
                    return {k: convert_string_to_datetime(v) for k, v in obj.items()}
                elif isinstance(obj, list):
                    return [convert_string_to_datetime(item) for item in obj]
                else:
                    return obj
            
            converted_data = convert_string_to_datetime(data)
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            metadata = self.load_metadata()
            if metadata:
                logger.info(f"‚úÖ –î–∞–Ω–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–µ–π –∑–∞–≥—Ä—É–∂–µ–Ω—ã:")
                logger.info(f"  üìä –°–∏–º–≤–æ–ª–æ–≤: {metadata['total_symbols']}")
                logger.info(f"  üì∞ –ù–æ–≤–æ—Å—Ç–µ–π: {metadata['total_news']}")
                logger.info(f"  üìÖ –ü–µ—Ä–∏–æ–¥: {metadata['date_range']['start']} - {metadata['date_range']['end']}")
            
            return converted_data
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π: {e}")
            return None
    
    def load_metadata(self) -> Optional[Dict[str, Any]]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö"""
        
        if not os.path.exists(self.metadata_file):
            return None
        
        try:
            with open(self.metadata_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö: {e}")
            return None
    
    def get_news_for_period(self, symbol: str, start_date: datetime, end_date: datetime) -> List[Dict]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Å–∏–º–≤–æ–ª–∞ –∏ –ø–µ—Ä–∏–æ–¥–∞"""
        
        news_data = self.load_news_data()
        if not news_data or symbol not in news_data:
            return []
        
        symbol_news = news_data[symbol]
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –ø–µ—Ä–∏–æ–¥—É
        filtered_news = [
            news for news in symbol_news
            if start_date <= news['published_at'] <= end_date
        ]
        
        return filtered_news
    
    def get_news_statistics(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ –Ω–æ–≤–æ—Å—Ç—è–º"""
        
        news_data = self.load_news_data()
        if not news_data:
            return {}
        
        stats = {
            'total_symbols': len(news_data),
            'total_news': sum(len(news) for news in news_data.values()),
            'symbols': {}
        }
        
        for symbol, news_list in news_data.items():
            if not news_list:
                continue
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Å–∏–º–≤–æ–ª—É
            symbol_stats = {
                'total_news': len(news_list),
                'categories': {},
                'sentiment_distribution': {
                    'very_positive': 0,
                    'positive': 0,
                    'neutral': 0,
                    'negative': 0,
                    'very_negative': 0
                },
                'impact_distribution': {
                    'very_high': 0,
                    'high': 0,
                    'medium': 0,
                    'low': 0
                },
                'avg_sentiment': 0.0,
                'avg_confidence': 0.0
            }
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –Ω–æ–≤–æ—Å—Ç–∏
            sentiment_scores = []
            confidence_scores = []
            
            for news in news_list:
                # –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø–æ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—é
                category = news.get('category', 'neutral')
                symbol_stats['sentiment_distribution'][category] += 1
                
                # –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø–æ –≤–ª–∏—è–Ω–∏—é
                impact = news.get('impact', 'low')
                symbol_stats['impact_distribution'][impact] += 1
                
                # –°–æ–±–∏—Ä–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏
                sentiment_scores.append(news.get('sentiment_score', 0.0))
                confidence_scores.append(news.get('confidence', 0.0))
            
            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è
            if sentiment_scores:
                symbol_stats['avg_sentiment'] = np.mean(sentiment_scores)
                symbol_stats['avg_confidence'] = np.mean(confidence_scores)
            
            stats['symbols'][symbol] = symbol_stats
        
        return stats
    
    def export_to_csv(self, output_file: str = None):
        """–≠–∫—Å–ø–æ—Ä—Ç –Ω–æ–≤–æ—Å—Ç–µ–π –≤ CSV —Ñ–æ—Ä–º–∞—Ç"""
        
        if output_file is None:
            output_file = os.path.join(self.data_dir, "news_3year_data.csv")
        
        news_data = self.load_news_data()
        if not news_data:
            logger.error("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞")
            return
        
        logger.info(f"üìä –≠–∫—Å–ø–æ—Ä—Ç –Ω–æ–≤–æ—Å—Ç–µ–π –≤ CSV: {output_file}")
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è CSV
        csv_data = []
        for symbol, news_list in news_data.items():
            for news in news_list:
                csv_data.append({
                    'symbol': symbol,
                    'title': news['title'],
                    'content': news['content'],
                    'published_at': news['published_at'],
                    'source': news['source'],
                    'sentiment_score': news['sentiment_score'],
                    'confidence': news['confidence'],
                    'impact': news['impact'],
                    'category': news.get('category', 'neutral'),
                    'id': news.get('id', '')
                })
        
        # –°–æ–∑–¥–∞–µ–º DataFrame –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º
        df = pd.DataFrame(csv_data)
        df.to_csv(output_file, index=False, encoding='utf-8')
        
        logger.info(f"‚úÖ –≠–∫—Å–ø–æ—Ä—Ç –∑–∞–≤–µ—Ä—à–µ–Ω: {len(csv_data)} –∑–∞–ø–∏—Å–µ–π –≤ {output_file}")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π –∑–∞ 3 –≥–æ–¥–∞"""
    
    # –°–∏–º–≤–æ–ª—ã –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –Ω–æ–≤–æ—Å—Ç–µ–π
    symbols = ['SBER', 'GAZP', 'LKOH', 'NVTK', 'ROSN', 'TATN', 'MGNT', 'MTSS', 'PIKK', 'IRAO', 'SGZH']
    
    # –ü–µ—Ä–∏–æ–¥ 3 –≥–æ–¥–∞
    start_date = datetime(2022, 9, 19)
    end_date = datetime(2025, 9, 2)
    
    # –°–æ–∑–¥–∞–µ–º –º–µ–Ω–µ–¥–∂–µ—Ä
    manager = NewsDataManager()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ –¥–∞–Ω–Ω—ã–µ
    existing_data = manager.load_news_data()
    if existing_data:
        logger.info("üìÇ –î–∞–Ω–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–µ–π —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        stats = manager.get_news_statistics()
        logger.info(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö:")
        logger.info(f"  üì∞ –í—Å–µ–≥–æ –Ω–æ–≤–æ—Å—Ç–µ–π: {stats['total_news']}")
        logger.info(f"  üìä –°–∏–º–≤–æ–ª–æ–≤: {stats['total_symbols']}")
        
        # –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º –≤ CSV
        manager.export_to_csv()
        
    else:
        logger.info("üîÑ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π...")
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –Ω–æ–≤–æ—Å—Ç–∏
        news_data = manager.generate_3year_news(symbols, start_date, end_date)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ
        manager.save_news_data(news_data)
        
        # –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º –≤ CSV
        manager.export_to_csv()
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        stats = manager.get_news_statistics()
        logger.info(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:")
        logger.info(f"  üì∞ –í—Å–µ–≥–æ –Ω–æ–≤–æ—Å—Ç–µ–π: {stats['total_news']}")
        logger.info(f"  üìä –°–∏–º–≤–æ–ª–æ–≤: {stats['total_symbols']}")

if __name__ == "__main__":
    main()
