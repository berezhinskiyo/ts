#!/usr/bin/env python3
"""
–£–ª—É—á—à–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –Ω–æ–≤–æ—Å—Ç–µ–π —Å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π —Ä–µ–∞–ª—å–Ω—ã—Ö API
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ–π —Ä–∞–±–æ—Ç—ã
"""

import os
import sys
import json
import time
import logging
import requests
import asyncio
import aiohttp
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass
from abc import ABC, abstractmethod
import hashlib
import sqlite3
from pathlib import Path

# NLP –∏–º–ø–æ—Ä—Ç—ã
try:
    from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification
    import torch
    TRANSFORMERS_AVAILABLE = True
except ImportError:
    TRANSFORMERS_AVAILABLE = False
    print("‚ö†Ô∏è Transformers –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install transformers torch")

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

@dataclass
class NewsItem:
    """–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –Ω–æ–≤–æ—Å—Ç–∏"""
    title: str
    content: str
    published_at: datetime
    source: str
    url: str = ""
    symbol: str = ""
    sentiment_score: float = 0.0
    confidence: float = 0.0

class NewsCache:
    """–ö—ç—à –¥–ª—è –Ω–æ–≤–æ—Å—Ç–µ–π —Å SQLite"""
    
    def __init__(self, cache_file: str = "news_cache.db"):
        self.cache_file = cache_file
        self.init_database()
    
    def init_database(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –∫—ç—à–∞"""
        conn = sqlite3.connect(self.cache_file)
        cursor = conn.cursor()
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS news_cache (
                id TEXT PRIMARY KEY,
                symbol TEXT,
                title TEXT,
                content TEXT,
                published_at TEXT,
                source TEXT,
                url TEXT,
                sentiment_score REAL,
                confidence REAL,
                cached_at TEXT
            )
        ''')
        
        # –°–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_symbol_time 
            ON news_cache(symbol, published_at)
        ''')
        
        conn.commit()
        conn.close()
    
    def get_cache_key(self, symbol: str, days_back: int) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–ª—é—á–∞ –∫—ç—à–∞"""
        return hashlib.md5(f"{symbol}_{days_back}_{datetime.now().strftime('%Y-%m-%d')}".encode()).hexdigest()
    
    def get_cached_news(self, symbol: str, days_back: int) -> List[NewsItem]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π"""
        conn = sqlite3.connect(self.cache_file)
        cursor = conn.cursor()
        
        cutoff_time = datetime.now() - timedelta(days=days_back)
        
        cursor.execute('''
            SELECT title, content, published_at, source, url, sentiment_score, confidence
            FROM news_cache 
            WHERE symbol = ? AND published_at >= ?
            ORDER BY published_at DESC
        ''', (symbol, cutoff_time.isoformat()))
        
        news_items = []
        for row in cursor.fetchall():
            news_items.append(NewsItem(
                title=row[0],
                content=row[1],
                published_at=datetime.fromisoformat(row[2]),
                source=row[3],
                url=row[4],
                sentiment_score=row[5],
                confidence=row[6]
            ))
        
        conn.close()
        return news_items
    
    def cache_news(self, symbol: str, news_items: List[NewsItem]):
        """–ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–µ–π"""
        conn = sqlite3.connect(self.cache_file)
        cursor = conn.cursor()
        
        for news in news_items:
            news_id = hashlib.md5(f"{news.title}_{news.published_at}".encode()).hexdigest()
            
            cursor.execute('''
                INSERT OR REPLACE INTO news_cache 
                (id, symbol, title, content, published_at, source, url, sentiment_score, confidence, cached_at)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                news_id, symbol, news.title, news.content, 
                news.published_at.isoformat(), news.source, news.url,
                news.sentiment_score, news.confidence, datetime.now().isoformat()
            ))
        
        conn.commit()
        conn.close()

class NewsProvider(ABC):
    """–ê–±—Å—Ç—Ä–∞–∫—Ç–Ω—ã–π –∫–ª–∞—Å—Å –¥–ª—è –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤ –Ω–æ–≤–æ—Å—Ç–µ–π"""
    
    @abstractmethod
    async def get_news(self, symbol: str, days_back: int = 7) -> List[NewsItem]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è —Å–∏–º–≤–æ–ª–∞"""
        pass
    
    @abstractmethod
    def get_name(self) -> str:
        """–ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞"""
        pass

class NewsAPIProvider(NewsProvider):
    """–ü—Ä–æ–≤–∞–π–¥–µ—Ä NewsAPI"""
    
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.base_url = "https://newsapi.org/v2/everything"
        self.session = None
    
    async def get_news(self, symbol: str, days_back: int = 7) -> List[NewsItem]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–µ–π —á–µ—Ä–µ–∑ NewsAPI"""
        if not self.session:
            self.session = aiohttp.ClientSession()
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å
        params = {
            'q': f'{symbol} OR "{symbol}" stock OR "{symbol}" shares',
            'language': 'en',
            'sortBy': 'publishedAt',
            'from': (datetime.now() - timedelta(days=days_back)).strftime('%Y-%m-%d'),
            'apiKey': self.api_key,
            'pageSize': 50
        }
        
        try:
            async with self.session.get(self.base_url, params=params) as response:
                if response.status == 200:
                    data = await response.json()
                    news_items = []
                    
                    for article in data.get('articles', []):
                        if article.get('title') and article.get('content'):
                            news_items.append(NewsItem(
                                title=article['title'],
                                content=article['content'] or article['description'] or '',
                                published_at=datetime.fromisoformat(article['publishedAt'].replace('Z', '+00:00')),
                                source=article['source']['name'],
                                url=article['url'],
                                symbol=symbol
                            ))
                    
                    return news_items
                else:
                    logger.error(f"NewsAPI error: {response.status}")
                    return []
        
        except Exception as e:
            logger.error(f"Error fetching news from NewsAPI: {e}")
            return []
    
    def get_name(self) -> str:
        return "NewsAPI"

class AlphaVantageProvider(NewsProvider):
    """–ü—Ä–æ–≤–∞–π–¥–µ—Ä Alpha Vantage News & Sentiment"""
    
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.base_url = "https://www.alphavantage.co/query"
        self.session = None
    
    async def get_news(self, symbol: str, days_back: int = 7) -> List[NewsItem]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–µ–π —á–µ—Ä–µ–∑ Alpha Vantage"""
        if not self.session:
            self.session = aiohttp.ClientSession()
        
        params = {
            'function': 'NEWS_SENTIMENT',
            'tickers': symbol,
            'apikey': self.api_key,
            'limit': 50
        }
        
        try:
            async with self.session.get(self.base_url, params=params) as response:
                if response.status == 200:
                    data = await response.json()
                    news_items = []
                    
                    for article in data.get('feed', []):
                        if article.get('title') and article.get('summary'):
                            # –ü–æ–ª—É—á–∞–µ–º —Å–µ–Ω—Ç–∏–º–µ–Ω—Ç –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ —Ç–∏–∫–µ—Ä–∞
                            sentiment_score = 0.0
                            confidence = 0.0
                            
                            for ticker_sentiment in article.get('ticker_sentiment', []):
                                if ticker_sentiment['ticker'] == symbol:
                                    sentiment_score = float(ticker_sentiment['relevance_score'])
                                    confidence = float(ticker_sentiment['ticker_sentiment_score'])
                                    break
                            
                            news_items.append(NewsItem(
                                title=article['title'],
                                content=article['summary'],
                                published_at=datetime.fromisoformat(article['time_published'].replace('Z', '+00:00')),
                                source=article['source'],
                                url=article['url'],
                                symbol=symbol,
                                sentiment_score=sentiment_score,
                                confidence=confidence
                            ))
                    
                    return news_items
                else:
                    logger.error(f"Alpha Vantage error: {response.status}")
                    return []
        
        except Exception as e:
            logger.error(f"Error fetching news from Alpha Vantage: {e}")
            return []
    
    def get_name(self) -> str:
        return "Alpha Vantage"

class YahooFinanceProvider(NewsProvider):
    """–ü—Ä–æ–≤–∞–π–¥–µ—Ä Yahoo Finance (–Ω–µ–æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π)"""
    
    def __init__(self):
        self.base_url = "https://query1.finance.yahoo.com/v1/finance/search"
        self.session = None
    
    async def get_news(self, symbol: str, days_back: int = 7) -> List[NewsItem]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–µ–π —á–µ—Ä–µ–∑ Yahoo Finance"""
        if not self.session:
            self.session = aiohttp.ClientSession()
        
        params = {
            'q': symbol,
            'quotesCount': 1,
            'newsCount': 50
        }
        
        try:
            async with self.session.get(self.base_url, params=params) as response:
                if response.status == 200:
                    data = await response.json()
                    news_items = []
                    
                    for article in data.get('news', []):
                        if article.get('title') and article.get('summary'):
                            news_items.append(NewsItem(
                                title=article['title'],
                                content=article['summary'],
                                published_at=datetime.fromtimestamp(article['providerPublishTime']),
                                source=article['publisher'],
                                url=article['link'],
                                symbol=symbol
                            ))
                    
                    return news_items
                else:
                    logger.error(f"Yahoo Finance error: {response.status}")
                    return []
        
        except Exception as e:
            logger.error(f"Error fetching news from Yahoo Finance: {e}")
            return []
    
    def get_name(self) -> str:
        return "Yahoo Finance"

class EnhancedNewsSentimentAnalyzer:
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –Ω–æ–≤–æ—Å—Ç–µ–π —Å –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º–∏"""
    
    def __init__(self, config_file: str = "news_config.json"):
        self.config = self.load_config(config_file)
        self.cache = NewsCache()
        self.providers = self.init_providers()
        self.sentiment_pipeline = self.init_sentiment_models()
        
        logger.info(f"‚úÖ Enhanced News Analyzer –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —Å {len(self.providers)} –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞–º–∏")
    
    def load_config(self, config_file: str) -> Dict:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        default_config = {
            "providers": {
                "newsapi": {"enabled": False, "api_key": ""},
                "alphavantage": {"enabled": False, "api_key": ""},
                "yahoofinance": {"enabled": True, "api_key": ""}
            },
            "cache": {
                "enabled": True,
                "ttl_hours": 1
            },
            "sentiment": {
                "use_financial_model": True,
                "confidence_threshold": 0.3
            }
        }
        
        if os.path.exists(config_file):
            try:
                with open(config_file, 'r', encoding='utf-8') as f:
                    user_config = json.load(f)
                    default_config.update(user_config)
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {e}")
        
        return default_config
    
    def init_providers(self) -> List[NewsProvider]:
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤ –Ω–æ–≤–æ—Å—Ç–µ–π"""
        providers = []
        
        if self.config["providers"]["newsapi"]["enabled"] and self.config["providers"]["newsapi"]["api_key"]:
            providers.append(NewsAPIProvider(self.config["providers"]["newsapi"]["api_key"]))
        
        if self.config["providers"]["alphavantage"]["enabled"] and self.config["providers"]["alphavantage"]["api_key"]:
            providers.append(AlphaVantageProvider(self.config["providers"]["alphavantage"]["api_key"]))
        
        if self.config["providers"]["yahoofinance"]["enabled"]:
            providers.append(YahooFinanceProvider())
        
        return providers
    
    def init_sentiment_models(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π –∞–Ω–∞–ª–∏–∑–∞ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π"""
        if not TRANSFORMERS_AVAILABLE:
            logger.warning("Transformers –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω, –∞–Ω–∞–ª–∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π –æ—Ç–∫–ª—é—á–µ–Ω")
            return None
        
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º FinBERT –¥–ª—è —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π
            if self.config["sentiment"]["use_financial_model"]:
                pipeline = pipeline(
                    "text-classification",
                    model="ProsusAI/finbert",
                    return_all_scores=True
                )
            else:
                pipeline = pipeline(
                    "sentiment-analysis",
                    model="cardiffnlp/twitter-roberta-base-sentiment-latest",
                    return_all_scores=True
                )
            
            logger.info("‚úÖ –ú–æ–¥–µ–ª—å –∞–Ω–∞–ª–∏–∑–∞ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            return pipeline
        
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ –∞–Ω–∞–ª–∏–∑–∞ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π: {e}")
            return None
    
    async def get_news_for_symbol(self, symbol: str, days_back: int = 7) -> List[NewsItem]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è —Å–∏–º–≤–æ–ª–∞ –∏–∑ –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤"""
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
        if self.config["cache"]["enabled"]:
            cached_news = self.cache.get_cached_news(symbol, days_back)
            if cached_news:
                logger.info(f"üì∞ –ù–∞–π–¥–µ–Ω–æ {len(cached_news)} –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è {symbol}")
                return cached_news
        
        # –ü–æ–ª—É—á–∞–µ–º –Ω–æ–≤–æ—Å—Ç–∏ –∏–∑ –≤—Å–µ—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤
        all_news = []
        
        for provider in self.providers:
            try:
                logger.info(f"üîç –ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è {symbol} –∏–∑ {provider.get_name()}")
                news = await provider.get_news(symbol, days_back)
                all_news.extend(news)
                logger.info(f"üì∞ –ü–æ–ª—É—á–µ–Ω–æ {len(news)} –Ω–æ–≤–æ—Å—Ç–µ–π –∏–∑ {provider.get_name()}")
                
                # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
                await asyncio.sleep(0.1)
                
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π –∏–∑ {provider.get_name()}: {e}")
        
        # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫—É
        unique_news = []
        seen_titles = set()
        
        for news in all_news:
            title_hash = hashlib.md5(news.title.lower().encode()).hexdigest()
            if title_hash not in seen_titles:
                seen_titles.add(title_hash)
                unique_news.append(news)
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è –¥–ª—è –Ω–æ–≤–æ—Å—Ç–µ–π –±–µ–∑ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        for news in unique_news:
            if news.sentiment_score == 0.0 and self.sentiment_pipeline:
                sentiment = self.analyze_sentiment(news.title + " " + news.content)
                news.sentiment_score = sentiment['score']
                news.confidence = sentiment['confidence']
        
        # –ö—ç—à–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        if self.config["cache"]["enabled"] and unique_news:
            self.cache.cache_news(symbol, unique_news)
        
        logger.info(f"üìä –ò—Ç–æ–≥–æ –ø–æ–ª—É—á–µ–Ω–æ {len(unique_news)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è {symbol}")
        return unique_news
    
    def analyze_sentiment(self, text: str) -> Dict[str, float]:
        """–ê–Ω–∞–ª–∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞"""
        if not text or not self.sentiment_pipeline:
            return {'score': 0.0, 'confidence': 0.0}
        
        try:
            results = self.sentiment_pipeline(text[:512])  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —á–∏—Å–ª–æ–≤–æ–π —Ñ–æ—Ä–º–∞—Ç
            positive_score = 0.0
            negative_score = 0.0
            
            for result in results[0]:
                label = result['label'].lower()
                score = result['score']
                
                if 'positive' in label or 'bullish' in label:
                    positive_score = score
                elif 'negative' in label or 'bearish' in label:
                    negative_score = score
            
            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –æ–±—â–∏–π —Å–µ–Ω—Ç–∏–º–µ–Ω—Ç (-1 –¥–æ 1)
            sentiment_score = positive_score - negative_score
            confidence = max(positive_score, negative_score)
            
            return {
                'score': sentiment_score,
                'confidence': confidence
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è: {e}")
            return {'score': 0.0, 'confidence': 0.0}
    
    def calculate_aggregate_sentiment(self, news_list: List[NewsItem]) -> Dict[str, float]:
        """–†–∞—Å—á–µ—Ç –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π"""
        if not news_list:
            return {
                'sentiment_score': 0.0,
                'confidence': 0.0,
                'news_count': 0,
                'positive_ratio': 0.5
            }
        
        total_sentiment = 0.0
        total_confidence = 0.0
        weight_sum = 0.0
        positive_count = 0
        
        for news in news_list:
            # –í–∑–≤–µ—à–∏–≤–∞–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏ (–±–æ–ª–µ–µ —Å–≤–µ–∂–∏–µ –Ω–æ–≤–æ—Å—Ç–∏ –≤–∞–∂–Ω–µ–µ)
            hours_ago = (datetime.now() - news.published_at).total_seconds() / 3600
            time_weight = max(0.1, 1.0 - hours_ago / (24 * 7))  # –ó–∞ –Ω–µ–¥–µ–ª—é –≤–µ—Å –ø–∞–¥–∞–µ—Ç –¥–æ 0.1
            
            # –í–∑–≤–µ—à–∏–≤–∞–µ–º –ø–æ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
            confidence_weight = news.confidence if news.confidence > 0 else 0.5
            
            # –û–±—â–∏–π –≤–µ—Å
            weight = time_weight * confidence_weight
            
            total_sentiment += news.sentiment_score * weight
            total_confidence += news.confidence * weight
            weight_sum += weight
            
            if news.sentiment_score > 0:
                positive_count += 1
        
        avg_sentiment = total_sentiment / weight_sum if weight_sum > 0 else 0.0
        avg_confidence = total_confidence / weight_sum if weight_sum > 0 else 0.0
        positive_ratio = positive_count / len(news_list)
        
        return {
            'sentiment_score': avg_sentiment,
            'confidence': avg_confidence,
            'news_count': len(news_list),
            'positive_ratio': positive_ratio
        }
    
    async def get_market_sentiment(self, symbols: List[str], days_back: int = 7) -> Dict[str, Dict[str, float]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π —Ä—ã–Ω–∫–∞ –¥–ª—è —Å–ø–∏—Å–∫–∞ —Å–∏–º–≤–æ–ª–æ–≤"""
        results = {}
        
        for symbol in symbols:
            try:
                news = await self.get_news_for_symbol(symbol, days_back)
                sentiment = self.calculate_aggregate_sentiment(news)
                results[symbol] = sentiment
                
                logger.info(f"üìà {symbol}: Sentiment={sentiment['sentiment_score']:.3f}, "
                          f"Confidence={sentiment['confidence']:.3f}, "
                          f"News={sentiment['news_count']}")
                
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π –¥–ª—è {symbol}: {e}")
                results[symbol] = {
                    'sentiment_score': 0.0,
                    'confidence': 0.0,
                    'news_count': 0,
                    'positive_ratio': 0.5
                }
        
        return results
    
    async def close(self):
        """–ó–∞–∫—Ä—ã—Ç–∏–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π"""
        for provider in self.providers:
            if hasattr(provider, 'session') and provider.session:
                await provider.session.close()

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
async def main():
    """–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ –Ω–æ–≤–æ—Å—Ç–µ–π"""
    
    # –°–æ–∑–¥–∞–µ–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä
    analyzer = EnhancedNewsSentimentAnalyzer()
    
    # –ü–æ–ª—É—á–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è –¥–ª—è —Å–ø–∏—Å–∫–∞ —Å–∏–º–≤–æ–ª–æ–≤
    symbols = ['AAPL', 'GOOGL', 'MSFT', 'TSLA']
    sentiments = await analyzer.get_market_sentiment(symbols, days_back=3)
    
    # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print("\nüìä –ê–ù–ê–õ–ò–ó –ù–ê–°–¢–†–û–ï–ù–ò–ô –†–´–ù–ö–ê")
    print("=" * 50)
    
    for symbol, sentiment in sentiments.items():
        print(f"{symbol}:")
        print(f"  Sentiment Score: {sentiment['sentiment_score']:.3f}")
        print(f"  Confidence: {sentiment['confidence']:.3f}")
        print(f"  News Count: {sentiment['news_count']}")
        print(f"  Positive Ratio: {sentiment['positive_ratio']:.3f}")
        print()
    
    # –ó–∞–∫—Ä—ã–≤–∞–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
    await analyzer.close()

if __name__ == "__main__":
    asyncio.run(main())
