#!/usr/bin/env python3
"""
–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∑–∞ 3 –≥–æ–¥–∞: –∑–∞–≥—Ä—É–∑–∫–∞ –º–∏–Ω—É—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö, –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
"""

import os
import sys
import json
import time
import logging
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import requests
from typing import Dict, List, Optional, Tuple
import warnings
warnings.filterwarnings('ignore')

# ML –∏–º–ø–æ—Ä—Ç—ã
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, IsolationForest
from sklearn.linear_model import Ridge, LinearRegression
from sklearn.svm import SVR
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.decomposition import PCA
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
from sklearn.feature_selection import SelectKBest, f_regression

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('3year_analysis.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class DataDownloader:
    """–ö–ª–∞—Å—Å –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –º–∏–Ω—É—Ç–Ω—ã—Ö –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö —Å MOEX"""
    
    def __init__(self):
        self.base_url = "https://iss.moex.com/iss/"
        self.data_dir = "data/3year_minute_data"
        os.makedirs(self.data_dir, exist_ok=True)
    
    def download_instrument_data(self, symbol: str, years: int = 3) -> pd.DataFrame:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –º–∏–Ω—É—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∑–∞ —É–∫–∞–∑–∞–Ω–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª–µ—Ç"""
        logger.info(f"üì• –ó–∞–≥—Ä—É–∂–∞–µ–º –º–∏–Ω—É—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è {symbol} –∑–∞ {years} –ª–µ—Ç...")
        
        all_data = []
        end_date = datetime.now()
        start_date = end_date - timedelta(days=years * 365)
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞—Å—Ç–∏ –ø–æ 30 –¥–Ω–µ–π (–∏–∑-–∑–∞ –ª–∏–º–∏—Ç–∞ 500 –∑–∞–ø–∏—Å–µ–π)
        current_date = start_date
        batch_size = 30  # –¥–Ω–µ–π
        
        while current_date < end_date:
            batch_end = min(current_date + timedelta(days=batch_size), end_date)
            
            try:
                url = f"{self.base_url}engines/stock/markets/shares/boards/TQBR/securities/{symbol}/candles.json"
                params = {
                    'from': current_date.strftime('%Y-%m-%d'),
                    'till': batch_end.strftime('%Y-%m-%d'),
                    'interval': 1  # 1 –º–∏–Ω—É—Ç–∞
                }
                
                response = requests.get(url, params=params, timeout=30)
                
                if response.status_code == 200:
                    data = response.json()
                    candles = data['candles']['data']
                    
                    if candles:
                        df_batch = pd.DataFrame(candles, columns=[
                            'open', 'close', 'high', 'low', 'value', 'volume', 'begin', 'end'
                        ])
                        df_batch['begin'] = pd.to_datetime(df_batch['begin'])
                        df_batch['end'] = pd.to_datetime(df_batch['end'])
                        df_batch['symbol'] = symbol
                        
                        all_data.append(df_batch)
                        logger.info(f"  ‚úÖ {symbol}: {len(candles)} –∑–∞–ø–∏—Å–µ–π –∑–∞ {current_date.strftime('%Y-%m-%d')} - {batch_end.strftime('%Y-%m-%d')}")
                    else:
                        logger.warning(f"  ‚ö†Ô∏è {symbol}: –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –∑–∞ {current_date.strftime('%Y-%m-%d')} - {batch_end.strftime('%Y-%m-%d')}")
                else:
                    logger.error(f"  ‚ùå {symbol}: –û—à–∏–±–∫–∞ {response.status_code} –∑–∞ {current_date.strftime('%Y-%m-%d')}")
                
                current_date = batch_end
                time.sleep(0.3)  # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
                
            except Exception as e:
                logger.error(f"  ‚ùå {symbol}: –û—à–∏–±–∫–∞ –∑–∞ {current_date.strftime('%Y-%m-%d')}: {e}")
                current_date = batch_end
                time.sleep(1)
        
        if all_data:
            df = pd.concat(all_data, ignore_index=True)
            df = df.sort_values('begin').reset_index(drop=True)
            
            # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
            df = df.drop_duplicates(subset=['begin']).reset_index(drop=True)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ
            filename = f"{self.data_dir}/{symbol}_3year_minute.csv"
            df.to_csv(filename, index=False)
            logger.info(f"üíæ {symbol}: –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(df)} –∑–∞–ø–∏—Å–µ–π –≤ {filename}")
            
            return df
        else:
            logger.error(f"‚ùå {symbol}: –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ")
            return pd.DataFrame()
    
    def download_all_instruments(self, symbols: List[str], years: int = 3) -> Dict[str, pd.DataFrame]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤—Å–µ—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤"""
        logger.info(f"üöÄ –ù–∞—á–∏–Ω–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É –º–∏–Ω—É—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {len(symbols)} –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –∑–∞ {years} –ª–µ—Ç")
        
        all_data = {}
        
        for symbol in symbols:
            try:
                df = self.download_instrument_data(symbol, years)
                if not df.empty:
                    all_data[symbol] = df
                else:
                    logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è {symbol}")
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {symbol}: {e}")
        
        logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {len(all_data)} –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤")
        return all_data

class TechnicalIndicators:
    """–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∫–ª–∞—Å—Å –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤"""
    
    @staticmethod
    def sma(data: pd.Series, window: int) -> pd.Series:
        """–ü—Ä–æ—Å—Ç–∞—è —Å–∫–æ–ª—å–∑—è—â–∞—è —Å—Ä–µ–¥–Ω—è—è"""
        return data.rolling(window=window).mean()
    
    @staticmethod
    def ema(data: pd.Series, window: int) -> pd.Series:
        """–≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è —Å–∫–æ–ª—å–∑—è—â–∞—è —Å—Ä–µ–¥–Ω—è—è"""
        return data.ewm(span=window).mean()
    
    @staticmethod
    def rsi(data: pd.Series, window: int = 14) -> pd.Series:
        """–ò–Ω–¥–µ–∫—Å –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ–π —Å–∏–ª—ã"""
        delta = data.diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()
        rs = gain / loss
        return 100 - (100 / (1 + rs))
    
    @staticmethod
    def macd(data: pd.Series, fast: int = 12, slow: int = 26, signal: int = 9) -> Tuple[pd.Series, pd.Series, pd.Series]:
        """MACD –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä"""
        ema_fast = TechnicalIndicators.ema(data, fast)
        ema_slow = TechnicalIndicators.ema(data, slow)
        macd_line = ema_fast - ema_slow
        signal_line = TechnicalIndicators.ema(macd_line, signal)
        histogram = macd_line - signal_line
        return macd_line, signal_line, histogram
    
    @staticmethod
    def bollinger_bands(data: pd.Series, window: int = 20, std_dev: float = 2) -> Tuple[pd.Series, pd.Series, pd.Series]:
        """–ü–æ–ª–æ—Å—ã –ë–æ–ª–ª–∏–Ω–¥–∂–µ—Ä–∞"""
        sma = TechnicalIndicators.sma(data, window)
        std = data.rolling(window=window).std()
        upper = sma + (std * std_dev)
        lower = sma - (std * std_dev)
        return upper, sma, lower
    
    @staticmethod
    def atr(high: pd.Series, low: pd.Series, close: pd.Series, window: int = 14) -> pd.Series:
        """Average True Range"""
        tr1 = high - low
        tr2 = abs(high - close.shift(1))
        tr3 = abs(low - close.shift(1))
        tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)
        return tr.rolling(window=window).mean()
    
    @staticmethod
    def stochastic(high: pd.Series, low: pd.Series, close: pd.Series, k_window: int = 14, d_window: int = 3) -> Tuple[pd.Series, pd.Series]:
        """Stochastic Oscillator"""
        lowest_low = low.rolling(window=k_window).min()
        highest_high = high.rolling(window=k_window).max()
        k_percent = 100 * ((close - lowest_low) / (highest_high - lowest_low))
        d_percent = k_percent.rolling(window=d_window).mean()
        return k_percent, d_percent
    
    @staticmethod
    def williams_r(high: pd.Series, low: pd.Series, close: pd.Series, window: int = 14) -> pd.Series:
        """Williams %R"""
        highest_high = high.rolling(window=window).max()
        lowest_low = low.rolling(window=window).min()
        return -100 * ((highest_high - close) / (highest_high - lowest_low))
    
    @staticmethod
    def cci(high: pd.Series, low: pd.Series, close: pd.Series, window: int = 20) -> pd.Series:
        """Commodity Channel Index"""
        typical_price = (high + low + close) / 3
        sma_tp = typical_price.rolling(window=window).mean()
        mad = typical_price.rolling(window=window).apply(lambda x: np.mean(np.abs(x - x.mean())))
        return (typical_price - sma_tp) / (0.015 * mad)
    
    @staticmethod
    def create_comprehensive_features(df: pd.DataFrame) -> pd.DataFrame:
        """–°–æ–∑–¥–∞–Ω–∏–µ –≤—Å–µ—Ö —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤"""
        df = df.copy()
        
        # –û—Å–Ω–æ–≤–Ω—ã–µ —Å–∫–æ–ª—å–∑—è—â–∏–µ —Å—Ä–µ–¥–Ω–∏–µ
        for window in [5, 10, 20, 50, 100]:
            df[f'sma_{window}'] = TechnicalIndicators.sma(df['close'], window)
            df[f'ema_{window}'] = TechnicalIndicators.ema(df['close'], window)
        
        # RSI —Å —Ä–∞–∑–Ω—ã–º–∏ –ø–µ—Ä–∏–æ–¥–∞–º–∏
        for window in [14, 21]:
            df[f'rsi_{window}'] = TechnicalIndicators.rsi(df['close'], window)
        
        # MACD
        macd, signal, histogram = TechnicalIndicators.macd(df['close'])
        df['macd'] = macd
        df['macd_signal'] = signal
        df['macd_histogram'] = histogram
        
        # –ü–æ–ª–æ—Å—ã –ë–æ–ª–ª–∏–Ω–¥–∂–µ—Ä–∞
        bb_upper, bb_middle, bb_lower = TechnicalIndicators.bollinger_bands(df['close'])
        df['bb_upper'] = bb_upper
        df['bb_middle'] = bb_middle
        df['bb_lower'] = bb_lower
        df['bb_width'] = (bb_upper - bb_lower) / bb_middle
        df['bb_position'] = (df['close'] - bb_lower) / (bb_upper - bb_lower)
        
        # ATR
        df['atr'] = TechnicalIndicators.atr(df['high'], df['low'], df['close'])
        
        # Stochastic
        k_percent, d_percent = TechnicalIndicators.stochastic(df['high'], df['low'], df['close'])
        df['stoch_k'] = k_percent
        df['stoch_d'] = d_percent
        
        # Williams %R
        df['williams_r'] = TechnicalIndicators.williams_r(df['high'], df['low'], df['close'])
        
        # CCI
        df['cci'] = TechnicalIndicators.cci(df['high'], df['low'], df['close'])
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        df['price_change'] = df['close'].pct_change()
        df['volume_change'] = df['volume'].pct_change()
        df['high_low_ratio'] = df['high'] / df['low']
        df['close_open_ratio'] = df['close'] / df['open']
        df['body_size'] = abs(df['close'] - df['open']) / df['open']
        df['upper_shadow'] = (df['high'] - np.maximum(df['open'], df['close'])) / df['open']
        df['lower_shadow'] = (np.minimum(df['open'], df['close']) - df['low']) / df['open']
        
        # –í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å
        df['volatility_5'] = df['close'].rolling(5).std()
        df['volatility_20'] = df['close'].rolling(20).std()
        
        # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        df['hour'] = df['begin'].dt.hour
        df['day_of_week'] = df['begin'].dt.dayofweek
        df['month'] = df['begin'].dt.month
        df['is_market_open'] = ((df['hour'] >= 10) & (df['hour'] < 18)).astype(int)
        
        # –û–±—ä–µ–º–Ω—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
        df['volume_sma'] = df['volume'].rolling(20).mean()
        df['volume_ratio'] = df['volume'] / df['volume_sma']
        df['price_volume'] = df['close'] * df['volume']
        
        return df

class AdvancedMLTrainer:
    """–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –∫–ª–∞—Å—Å –¥–ª—è –æ–±—É—á–µ–Ω–∏—è ML –º–æ–¥–µ–ª–µ–π"""
    
    def __init__(self):
        self.models = {}
        self.scalers = {}
        self.feature_selectors = {}
        self.feature_importance = {}
        self.model_scores = {}
    
    def prepare_data(self, df: pd.DataFrame, target_column: str = 'future_return', 
                    lookback: int = 60, forecast_horizon: int = 5) -> Tuple[np.ndarray, np.ndarray, List[str]]:
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏"""
        # –°–æ–∑–¥–∞–µ–º —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é
        df['future_price'] = df['close'].shift(-forecast_horizon)
        df['future_return'] = (df['future_price'] / df['close'] - 1) * 100
        
        # –£–±–∏—Ä–∞–µ–º NaN
        df = df.dropna()
        
        # –í—ã–±–∏—Ä–∞–µ–º –≤—Å–µ —á–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        numeric_columns = df.select_dtypes(include=[np.number]).columns.tolist()
        feature_columns = [col for col in numeric_columns if col not in ['future_price', 'future_return', 'value']]
        
        # –°–æ–∑–¥–∞–µ–º —Å–∫–æ–ª—å–∑—è—â–∏–µ –æ–∫–Ω–∞
        X = []
        y = []
        
        for i in range(lookback, len(df) - forecast_horizon):
            window_data = df[feature_columns].iloc[i-lookback:i].values
            target_value = df[target_column].iloc[i]
            
            if not np.isnan(target_value):
                X.append(window_data.flatten())
                y.append(target_value)
        
        return np.array(X), np.array(y), feature_columns
    
    def train_models(self, X: np.ndarray, y: np.ndarray, symbol: str, feature_columns: List[str]):
        """–û–±—É—á–µ–Ω–∏–µ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö ML –º–æ–¥–µ–ª–µ–π —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π"""
        logger.info(f"ü§ñ –û–±—É—á–∞–µ–º –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è {symbol}...")
        
        # –†–∞–∑–¥–µ–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, shuffle=False
        )
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        # –í—ã–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        feature_selector = SelectKBest(score_func=f_regression, k=min(50, X_train_scaled.shape[1]))
        X_train_selected = feature_selector.fit_transform(X_train_scaled, y_train)
        X_test_selected = feature_selector.transform(X_test_scaled)
        
        # –ú–æ–¥–µ–ª–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        models_config = {
            'random_forest': RandomForestRegressor(
                n_estimators=200, 
                max_depth=15, 
                min_samples_split=5,
                min_samples_leaf=2,
                random_state=42,
                n_jobs=-1
            ),
            'gradient_boosting': GradientBoostingRegressor(
                n_estimators=200,
                learning_rate=0.1,
                max_depth=8,
                min_samples_split=5,
                random_state=42
            ),
            'ridge': Ridge(alpha=1.0),
            'svr': SVR(kernel='rbf', C=1.0, gamma='scale'),
            'linear_regression': LinearRegression()
        }
        
        results = {}
        
        for name, model in models_config.items():
            try:
                logger.info(f"  üîÑ –û–±—É—á–∞–µ–º {name}...")
                
                # –û–±—É—á–µ–Ω–∏–µ
                if name in ['ridge', 'svr', 'linear_regression']:
                    model.fit(X_train_selected, y_train)
                    y_pred = model.predict(X_test_selected)
                else:
                    model.fit(X_train, y_train)
                    y_pred = model.predict(X_test)
                
                # –û—Ü–µ–Ω–∫–∞
                mse = mean_squared_error(y_test, y_pred)
                r2 = r2_score(y_test, y_pred)
                mae = mean_absolute_error(y_test, y_pred)
                
                # –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è
                if name in ['ridge', 'svr', 'linear_regression']:
                    cv_scores = cross_val_score(model, X_train_selected, y_train, cv=5, scoring='r2')
                else:
                    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='r2')
                
                results[name] = {
                    'model': model,
                    'mse': mse,
                    'r2': r2,
                    'mae': mae,
                    'cv_mean': cv_scores.mean(),
                    'cv_std': cv_scores.std(),
                    'predictions': y_pred,
                    'actual': y_test
                }
                
                logger.info(f"    ‚úÖ {name}: MSE={mse:.4f}, R¬≤={r2:.4f}, MAE={mae:.4f}, CV={cv_scores.mean():.4f}¬±{cv_scores.std():.4f}")
                
            except Exception as e:
                logger.error(f"    ‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è {name}: {e}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        self.models[symbol] = results
        self.scalers[symbol] = scaler
        self.feature_selectors[symbol] = feature_selector
        
        return results

class UnsupervisedLearningAgent:
    """–ê–≥–µ–Ω—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –±–µ–∑ —É—á–∏—Ç–µ–ª—è"""
    
    def __init__(self):
        self.anomaly_detector = IsolationForest(contamination=0.1, random_state=42)
        self.clusterer = KMeans(n_clusters=5, random_state=42)
        self.pca = PCA(n_components=10)
        self.scaler = StandardScaler()
        self.is_trained = False
    
    def prepare_features(self, df: pd.DataFrame) -> np.ndarray:
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –±–µ–∑ —É—á–∏—Ç–µ–ª—è"""
        # –í—ã–±–∏—Ä–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        feature_columns = [
            'sma_20', 'ema_20', 'rsi_14', 'macd', 'bb_width', 'atr',
            'stoch_k', 'williams_r', 'cci', 'volatility_20', 'volume_ratio',
            'price_change', 'high_low_ratio', 'body_size'
        ]
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
        available_columns = [col for col in feature_columns if col in df.columns]
        
        if not available_columns:
            return np.array([])
        
        features = df[available_columns].fillna(0).values
        return features
    
    def train_unsupervised_models(self, df: pd.DataFrame):
        """–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –±–µ–∑ —É—á–∏—Ç–µ–ª—è"""
        logger.info("ü§ñ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –±–µ–∑ —É—á–∏—Ç–µ–ª—è...")
        
        features = self.prepare_features(df)
        if len(features) < 100:
            logger.warning("‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –±–µ–∑ —É—á–∏—Ç–µ–ª—è")
            return
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        features_scaled = self.scaler.fit_transform(features)
        
        # PCA –¥–ª—è —Å–Ω–∏–∂–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏
        features_pca = self.pca.fit_transform(features_scaled)
        
        # –û–±—É—á–µ–Ω–∏–µ –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞ –∞–Ω–æ–º–∞–ª–∏–π
        self.anomaly_detector.fit(features_pca)
        
        # –û–±—É—á–µ–Ω–∏–µ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏
        self.clusterer.fit(features_pca)
        
        self.is_trained = True
        logger.info("‚úÖ –ú–æ–¥–µ–ª–∏ –±–µ–∑ —É—á–∏—Ç–µ–ª—è –æ–±—É—á–µ–Ω—ã")
    
    def detect_anomalies(self, df: pd.DataFrame) -> np.ndarray:
        """–î–µ—Ç–µ–∫—Ü–∏—è –∞–Ω–æ–º–∞–ª–∏–π"""
        if not self.is_trained:
            return np.array([])
        
        features = self.prepare_features(df)
        if len(features) == 0:
            return np.array([])
        
        features_scaled = self.scaler.transform(features)
        features_pca = self.pca.transform(features_scaled)
        
        anomalies = self.anomaly_detector.predict(features_pca)
        return anomalies
    
    def get_market_regimes(self, df: pd.DataFrame) -> np.ndarray:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä—ã–Ω–æ—á–Ω—ã—Ö —Ä–µ–∂–∏–º–æ–≤"""
        if not self.is_trained:
            return np.array([])
        
        features = self.prepare_features(df)
        if len(features) == 0:
            return np.array([])
        
        features_scaled = self.scaler.transform(features)
        features_pca = self.pca.transform(features_scaled)
        
        clusters = self.clusterer.predict(features_pca)
        return clusters

class AdvancedStrategyTester:
    """–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –∫–ª–∞—Å—Å –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Ç–æ—Ä–≥–æ–≤—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π"""
    
    def __init__(self, initial_capital: float = 100000):
        self.initial_capital = initial_capital
        self.results = {}
    
    def test_ml_strategy(self, df: pd.DataFrame, models: Dict, symbol: str, 
                        unsupervised_agent: UnsupervisedLearningAgent) -> Dict:
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–π ML —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏"""
        logger.info(f"üìä –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—É—é ML —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –¥–ª—è {symbol}...")
        
        capital = self.initial_capital
        position = 0
        trades = []
        equity_history = []
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
        lookback = 60
        forecast_horizon = 5
        confidence_threshold = 0.6  # –ü–æ–≤—ã—à–µ–Ω–Ω—ã–π –ø–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        
        for i in range(lookback, len(df) - forecast_horizon):
            current_price = df['close'].iloc[i]
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            feature_columns = [col for col in df.columns if col not in ['begin', 'end', 'symbol', 'future_price', 'future_return', 'value']]
            window_data = df[feature_columns].iloc[i-lookback:i].values.flatten()
            
            # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –æ—Ç –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π
            predictions = []
            model_weights = []
            
            for model_name, model_data in models.items():
                try:
                    if model_name in ['ridge', 'svr', 'linear_regression']:
                        # –ù—É–∂–Ω–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∏ –≤—ã–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
                        window_scaled = models['scaler'].transform([window_data])
                        window_selected = models['feature_selector'].transform(window_scaled)
                        pred = model_data['model'].predict(window_selected)[0]
                    else:
                        pred = model_data['model'].predict([window_data])[0]
                    
                    predictions.append(pred)
                    # –í–µ—Å –º–æ–¥–µ–ª–∏ –æ—Å–Ω–æ–≤–∞–Ω –Ω–∞ R¬≤
                    model_weights.append(max(0, model_data['r2']))
                    
                except:
                    continue
            
            if not predictions:
                continue
            
            # –í–∑–≤–µ—à–µ–Ω–Ω–æ–µ —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
            if sum(model_weights) > 0:
                avg_prediction = np.average(predictions, weights=model_weights)
                confidence = 1.0 - (np.std(predictions) / (abs(avg_prediction) + 1e-6))
            else:
                avg_prediction = np.mean(predictions)
                confidence = 0.5
            
            # –ê–Ω–∞–ª–∏–∑ –∞–Ω–æ–º–∞–ª–∏–π –∏ —Ä–µ–∂–∏–º–æ–≤
            anomaly_signal = 0.0
            regime_signal = 0.0
            
            if unsupervised_agent.is_trained:
                current_data = df.iloc[max(0, i-100):i+1]
                anomalies = unsupervised_agent.detect_anomalies(current_data)
                regimes = unsupervised_agent.get_market_regimes(current_data)
                
                if len(anomalies) > 0 and anomalies[-1] == -1:
                    anomaly_signal = 0.3  # –ê–Ω–æ–º–∞–ª–∏—è –º–æ–∂–µ—Ç —É–∫–∞–∑—ã–≤–∞—Ç—å –Ω–∞ —Ä–∞–∑–≤–æ—Ä–æ—Ç
                
                if len(regimes) > 0:
                    current_regime = regimes[-1]
                    regime_signal = (current_regime - 2) * 0.1  # –¶–µ–Ω—Ç—Ä–∏—Ä—É–µ–º –≤–æ–∫—Ä—É–≥ 0
            
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å–∏–≥–Ω–∞–ª—ã
            final_signal = avg_prediction + anomaly_signal + regime_signal
            
            # –õ–æ–≥–∏–∫–∞ —Ç–æ—Ä–≥–æ–≤–ª–∏ —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º–∏ —É—Å–ª–æ–≤–∏—è–º–∏
            if final_signal > 0.5 and position == 0 and confidence > confidence_threshold:
                position = capital / current_price
                capital = 0
                trades.append({
                    'type': 'buy',
                    'price': current_price,
                    'time': df['begin'].iloc[i],
                    'prediction': avg_prediction,
                    'confidence': confidence,
                    'signal': final_signal
                })
            elif final_signal < -0.5 and position > 0 and confidence > confidence_threshold:
                capital = position * current_price
                position = 0
                trades.append({
                    'type': 'sell',
                    'price': current_price,
                    'time': df['begin'].iloc[i],
                    'prediction': avg_prediction,
                    'confidence': confidence,
                    'signal': final_signal
                })
            
            # –¢–µ–∫—É—â–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å –ø–æ—Ä—Ç—Ñ–µ–ª—è
            current_equity = capital + (position * current_price if position > 0 else 0)
            equity_history.append({
                'time': df['begin'].iloc[i],
                'equity': current_equity,
                'price': current_price
            })
        
        # –ó–∞–∫—Ä—ã–≤–∞–µ–º –ø–æ–∑–∏—Ü–∏—é –≤ –∫–æ–Ω—Ü–µ
        if position > 0:
            final_price = df['close'].iloc[-1]
            capital = position * final_price
            trades.append({
                'type': 'sell',
                'price': final_price,
                'time': df['begin'].iloc[-1],
                'prediction': 0,
                'confidence': 0,
                'signal': 0
            })
        
        # –†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫
        final_equity = capital
        total_return = (final_equity - self.initial_capital) / self.initial_capital * 100
        
        # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å–∞–¥–∫–∞
        equity_series = pd.Series([h['equity'] for h in equity_history])
        rolling_max = equity_series.expanding().max()
        drawdown = (equity_series - rolling_max) / rolling_max * 100
        max_drawdown = drawdown.min()
        
        # –í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å
        returns = equity_series.pct_change().dropna()
        volatility = returns.std() * np.sqrt(252 * 24 * 60) * 100  # –ì–æ–¥–æ–≤–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å
        
        # Sharpe ratio
        risk_free_rate = 0.05  # 5% –≥–æ–¥–æ–≤—ã—Ö
        excess_returns = returns - risk_free_rate / (252 * 24 * 60)
        sharpe_ratio = excess_returns.mean() / returns.std() * np.sqrt(252 * 24 * 60) if returns.std() > 0 else 0
        
        # Win rate
        if len(trades) >= 2:
            buy_trades = [t for t in trades if t['type'] == 'buy']
            sell_trades = [t for t in trades if t['type'] == 'sell']
            
            if len(buy_trades) > 0 and len(sell_trades) > 0:
                profitable_trades = 0
                total_trades = min(len(buy_trades), len(sell_trades))
                
                for i in range(total_trades):
                    if i < len(sell_trades):
                        profit = (sell_trades[i]['price'] - buy_trades[i]['price']) / buy_trades[i]['price']
                        if profit > 0:
                            profitable_trades += 1
                
                win_rate = (profitable_trades / total_trades) * 100 if total_trades > 0 else 0
            else:
                win_rate = 0
        else:
            win_rate = 0
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        avg_trade_duration = 0
        if len(trades) > 0:
            trade_durations = []
            for i in range(0, len(trades)-1, 2):
                if i+1 < len(trades):
                    duration = (trades[i+1]['time'] - trades[i]['time']).total_seconds() / 3600  # –≤ —á–∞—Å–∞—Ö
                    trade_durations.append(duration)
            avg_trade_duration = np.mean(trade_durations) if trade_durations else 0
        
        result = {
            'symbol': symbol,
            'initial_capital': self.initial_capital,
            'final_equity': final_equity,
            'total_return': total_return,
            'max_drawdown': max_drawdown,
            'volatility': volatility,
            'sharpe_ratio': sharpe_ratio,
            'win_rate': win_rate,
            'total_trades': len(trades),
            'avg_trade_duration_hours': avg_trade_duration,
            'trades': trades,
            'equity_history': equity_history
        }
        
        logger.info(f"  ‚úÖ {symbol}: –î–æ—Ö–æ–¥–Ω–æ—Å—Ç—å={total_return:.2f}%, –ü—Ä–æ—Å–∞–¥–∫–∞={max_drawdown:.2f}%, Sharpe={sharpe_ratio:.2f}, Win Rate={win_rate:.1f}%")
        
        return result
    
    def test_buy_hold_strategy(self, df: pd.DataFrame, symbol: str) -> Dict:
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ Buy & Hold"""
        logger.info(f"üìà –¢–µ—Å—Ç–∏—Ä—É–µ–º Buy & Hold –¥–ª—è {symbol}...")
        
        initial_price = df['close'].iloc[0]
        final_price = df['close'].iloc[-1]
        
        total_return = (final_price - initial_price) / initial_price * 100
        
        # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å–∞–¥–∫–∞
        rolling_max = df['close'].expanding().max()
        drawdown = (df['close'] - rolling_max) / rolling_max * 100
        max_drawdown = drawdown.min()
        
        # –í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å
        returns = df['close'].pct_change().dropna()
        volatility = returns.std() * np.sqrt(252 * 24 * 60) * 100
        
        # Sharpe ratio
        risk_free_rate = 0.05
        excess_returns = returns - risk_free_rate / (252 * 24 * 60)
        sharpe_ratio = excess_returns.mean() / returns.std() * np.sqrt(252 * 24 * 60) if returns.std() > 0 else 0
        
        result = {
            'symbol': symbol,
            'strategy': 'buy_hold',
            'initial_price': initial_price,
            'final_price': final_price,
            'total_return': total_return,
            'max_drawdown': max_drawdown,
            'volatility': volatility,
            'sharpe_ratio': sharpe_ratio,
            'win_rate': 100 if total_return > 0 else 0,
            'total_trades': 1
        }
        
        logger.info(f"  ‚úÖ {symbol} Buy & Hold: –î–æ—Ö–æ–¥–Ω–æ—Å—Ç—å={total_return:.2f}%, –ü—Ä–æ—Å–∞–¥–∫–∞={max_drawdown:.2f}%")
        
        return result

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    logger.info("üöÄ –ó–ê–ü–£–°–ö –ö–û–ú–ü–õ–ï–ö–°–ù–û–ì–û –ê–ù–ê–õ–ò–ó–ê –ó–ê 3 –ì–û–î–ê (–ú–ò–ù–£–¢–ù–´–ï –î–ê–ù–ù–´–ï)")
    logger.info("=" * 70)
    
    # –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    symbols = ['GAZP', 'SBER', 'PIKK', 'IRAO', 'SGZH']
    
    # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    logger.info("üì• –≠–¢–ê–ü 1: –ó–∞–≥—Ä—É–∑–∫–∞ –º–∏–Ω—É—Ç–Ω—ã—Ö –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö")
    downloader = DataDownloader()
    all_data = downloader.download_all_instruments(symbols, years=3)
    
    if not all_data:
        logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ. –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã.")
        return
    
    # 2. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
    logger.info("\nü§ñ –≠–¢–ê–ü 2: –û–±—É—á–µ–Ω–∏–µ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã—Ö ML –º–æ–¥–µ–ª–µ–π")
    trainer = AdvancedMLTrainer()
    indicators = TechnicalIndicators()
    unsupervised_agent = UnsupervisedLearningAgent()
    
    trained_models = {}
    
    for symbol, df in all_data.items():
        logger.info(f"üìä –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º {symbol}...")
        
        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
        df_with_features = indicators.create_comprehensive_features(df)
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        X, y, feature_columns = trainer.prepare_data(df_with_features)
        
        if len(X) > 200:  # –ú–∏–Ω–∏–º—É–º –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
            # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª–∏
            models = trainer.train_models(X, y, symbol, feature_columns)
            trained_models[symbol] = {
                'models': models,
                'data': df_with_features
            }
        else:
            logger.warning(f"‚ö†Ô∏è {symbol}: –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è ({len(X)} –∑–∞–ø–∏—Å–µ–π)")
    
    # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –±–µ–∑ —É—á–∏—Ç–µ–ª—è
    if trained_models:
        all_training_data = []
        for model_data in trained_models.values():
            all_training_data.append(model_data['data'])
        
        combined_df = pd.concat(all_training_data, ignore_index=True)
        unsupervised_agent.train_unsupervised_models(combined_df)
    
    # 3. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
    logger.info("\nüìä –≠–¢–ê–ü 3: –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–æ—Ä–≥–æ–≤—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π")
    tester = AdvancedStrategyTester()
    
    all_results = {}
    
    for symbol, model_data in trained_models.items():
        logger.info(f"üß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –¥–ª—è {symbol}...")
        
        df = model_data['data']
        models = model_data['models']
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º ML —Å—Ç—Ä–∞—Ç–µ–≥–∏—é
        ml_result = tester.test_ml_strategy(df, models, symbol, unsupervised_agent)
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º Buy & Hold
        bh_result = tester.test_buy_hold_strategy(df, symbol)
        
        all_results[symbol] = {
            'ml_strategy': ml_result,
            'buy_hold': bh_result
        }
    
    # 4. –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    logger.info("\nüìà –≠–¢–ê–ü 4: –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
    
    # –°–æ–∑–¥–∞–µ–º —Å–≤–æ–¥–Ω—É—é —Ç–∞–±–ª–∏—Ü—É
    summary_data = []
    
    for symbol, results in all_results.items():
        ml = results['ml_strategy']
        bh = results['buy_hold']
        
        summary_data.append({
            'Symbol': symbol,
            'ML_Return': f"{ml['total_return']:.2f}%",
            'ML_Drawdown': f"{ml['max_drawdown']:.2f}%",
            'ML_Sharpe': f"{ml['sharpe_ratio']:.2f}",
            'ML_Win_Rate': f"{ml['win_rate']:.1f}%",
            'ML_Trades': ml['total_trades'],
            'ML_Avg_Duration': f"{ml['avg_trade_duration_hours']:.1f}h",
            'BH_Return': f"{bh['total_return']:.2f}%",
            'BH_Drawdown': f"{bh['max_drawdown']:.2f}%",
            'BH_Sharpe': f"{bh['sharpe_ratio']:.2f}",
            'Outperformance': f"{ml['total_return'] - bh['total_return']:.2f}%"
        })
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    results_df = pd.DataFrame(summary_data)
    results_df.to_csv('3year_analysis_results.csv', index=False)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    def clean_for_json(obj):
        """–û—á–∏—Å—Ç–∫–∞ –æ–±—ä–µ–∫—Ç–∞ –æ—Ç —Ü–∏–∫–ª–∏—á–µ—Å–∫–∏—Ö —Å—Å—ã–ª–æ–∫ –∏ numpy —Ç–∏–ø–æ–≤"""
        if isinstance(obj, dict):
            return {k: clean_for_json(v) for k, v in obj.items() 
                   if k not in ['model', 'scaler', 'feature_selector', 'anomaly_detector', 'clusterer']}
        elif isinstance(obj, list):
            return [clean_for_json(item) for item in obj]
        elif isinstance(obj, np.integer):
            return int(obj)
        elif isinstance(obj, np.floating):
            return float(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        elif hasattr(obj, 'isoformat'):  # datetime
            return obj.isoformat()
        else:
            return obj
    
    with open('3year_detailed_results.json', 'w', encoding='utf-8') as f:
        clean_results = clean_for_json(all_results)
        json.dump(clean_results, f, ensure_ascii=False, indent=2)
    
    # –í—ã–≤–æ–¥–∏–º —Å–≤–æ–¥–∫—É
    logger.info("\nüìã –°–í–û–î–ö–ê –†–ï–ó–£–õ–¨–¢–ê–¢–û–í (3 –ì–û–î–ê, –ú–ò–ù–£–¢–ù–´–ï –î–ê–ù–ù–´–ï):")
    logger.info("=" * 70)
    print(results_df.to_string(index=False))
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    ml_returns = [float(r['ML_Return'].replace('%', '')) for r in summary_data]
    bh_returns = [float(r['BH_Return'].replace('%', '')) for r in summary_data]
    ml_sharpe = [float(r['ML_Sharpe']) for r in summary_data]
    ml_win_rates = [float(r['ML_Win_Rate'].replace('%', '')) for r in summary_data]
    
    logger.info(f"\nüìä –û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
    logger.info(f"  –°—Ä–µ–¥–Ω—è—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å ML: {np.mean(ml_returns):.2f}%")
    logger.info(f"  –°—Ä–µ–¥–Ω—è—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å Buy & Hold: {np.mean(bh_returns):.2f}%")
    logger.info(f"  –ü—Ä–µ–≤—ã—à–µ–Ω–∏–µ ML –Ω–∞–¥ Buy & Hold: {np.mean(ml_returns) - np.mean(bh_returns):.2f}%")
    logger.info(f"  –°—Ä–µ–¥–Ω–∏–π Sharpe ML: {np.mean(ml_sharpe):.2f}")
    logger.info(f"  –°—Ä–µ–¥–Ω–∏–π Win Rate ML: {np.mean(ml_win_rates):.1f}%")
    
    # –õ—É—á—à–∏–µ –∏ —Ö—É–¥—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    best_return_idx = np.argmax(ml_returns)
    worst_return_idx = np.argmin(ml_returns)
    
    logger.info(f"\nüèÜ –õ–£–ß–®–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´:")
    logger.info(f"  –õ—É—á—à–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å: {summary_data[best_return_idx]['Symbol']} ({summary_data[best_return_idx]['ML_Return']})")
    logger.info(f"  –õ—É—á—à–∏–π Sharpe: {summary_data[np.argmax(ml_sharpe)]['Symbol']} ({summary_data[np.argmax(ml_sharpe)]['ML_Sharpe']})")
    logger.info(f"  –õ—É—á—à–∏–π Win Rate: {summary_data[np.argmax(ml_win_rates)]['Symbol']} ({summary_data[np.argmax(ml_win_rates)]['ML_Win_Rate']})")
    
    logger.info(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã:")
    logger.info(f"  üìÑ –°–≤–æ–¥–∫–∞: 3year_analysis_results.csv")
    logger.info(f"  üìÑ –î–µ—Ç–∞–ª–∏: 3year_detailed_results.json")
    logger.info(f"  üìÑ –õ–æ–≥–∏: 3year_analysis.log")
    
    logger.info("\n‚úÖ –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–ï–ù!")

if __name__ == "__main__":
    main()
