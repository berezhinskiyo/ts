#!/usr/bin/env python3
"""
–°–µ—Ä–≤–∏—Å –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –∞–∫—Ç—É–∞–ª—å–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –∏ –∫–æ—Ç–∏—Ä–æ–≤–æ–∫ –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
–î–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π –∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
"""

import os
import sys
import json
import time
import asyncio
import logging
import schedule
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
import pandas as pd
import numpy as np
import requests
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# –ò–º–ø–æ—Ä—Ç—ã
from news_data_manager import NewsDataManager
from russian_news_analyzer import RussianNewsAnalyzer
from env_loader import load_env_file

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('data_update_service.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class MarketDataUpdater:
    """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ä—ã–Ω–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
    
    def __init__(self, data_dir: str = "data/"):
        self.data_dir = data_dir
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–∑ .env —Ñ–∞–π–ª–∞
        self.load_environment_variables()
        
        self.tbank_token = os.getenv('TBANK_TOKEN')
        self.symbols = ['SBER', 'GAZP', 'LKOH', 'NVTK', 'ROSN', 'TATN', 'MGNT', 'MTSS', 'PIKK', 'IRAO', 'SGZH']
        
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        os.makedirs(os.path.join(data_dir, 'real_time'), exist_ok=True)
        os.makedirs(os.path.join(data_dir, 'historical'), exist_ok=True)
        os.makedirs(os.path.join(data_dir, 'minute_data'), exist_ok=True)
        
        logger.info("‚úÖ –û–±–Ω–æ–≤–ª—è—Ç–µ–ª—å —Ä—ã–Ω–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    
    def load_environment_variables(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–∑ .env —Ñ–∞–π–ª–∞"""
        try:
            # –ü—É—Ç–∏ –∫ .env —Ñ–∞–π–ª–∞–º
            env_paths = [
                'config/environments/.env',
                'config/.env', 
                '.env'
            ]
            
            for path in env_paths:
                if os.path.exists(path):
                    load_env_file(path)
                    logger.info(f"‚úÖ –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑: {path}")
                    break
            else:
                logger.warning("‚ö†Ô∏è .env —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —Å–∏—Å—Ç–µ–º–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è")
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è: {e}")
    
    async def update_real_time_data(self):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏"""
        logger.info("üìä –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏...")
        
        if not self.tbank_token:
            logger.warning("‚ö†Ô∏è TBANK_TOKEN –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö")
            return
        
        try:
            # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Ü–µ–Ω—ã
            last_prices = {}
            data_summary = {
                'updated_at': datetime.now().isoformat(),
                'symbols': {},
                'total_symbols': len(self.symbols)
            }
            
            for symbol in self.symbols:
                try:
                    # –ó–¥–µ—Å—å –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Ä–µ–∞–ª—å–Ω—ã–π API –≤—ã–∑–æ–≤ –∫ T-Bank
                    # –î–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
                    price_data = await self.get_symbol_data(symbol)
                    
                    if price_data:
                        last_prices[symbol] = price_data
                        data_summary['symbols'][symbol] = {
                            'price': price_data.get('price', 0),
                            'change': price_data.get('change', 0),
                            'volume': price_data.get('volume', 0),
                            'updated_at': price_data.get('timestamp', datetime.now().isoformat())
                        }
                        
                        logger.debug(f"üìà {symbol}: {price_data.get('price', 0)} ({price_data.get('change', 0):+.2f}%)")
                
                except Exception as e:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {symbol}: {e}")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ
            await self.save_real_time_data(last_prices, data_summary)
            
            logger.info(f"‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –¥–ª—è {len(last_prices)} —Å–∏–º–≤–æ–ª–æ–≤")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏: {e}")
    
    async def get_symbol_data(self, symbol: str) -> Optional[Dict[str, Any]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –ø–æ —Å–∏–º–≤–æ–ª—É"""
        if not self.tbank_token:
            logger.warning(f"‚ö†Ô∏è TBANK_TOKEN –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–µ–º–æ-–¥–∞–Ω–Ω—ã–µ –¥–ª—è {symbol}")
            return await self.get_demo_symbol_data(symbol)
        
        try:
            # –ó–¥–µ—Å—å –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Ä–µ–∞–ª—å–Ω—ã–π API –≤—ã–∑–æ–≤ –∫ T-Bank
            # –ü–æ–∫–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–µ–º–æ-–¥–∞–Ω–Ω—ã–µ
            return await self.get_demo_symbol_data(symbol)
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {symbol}: {e}")
            return await self.get_demo_symbol_data(symbol)
    
    async def get_demo_symbol_data(self, symbol: str) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–µ–º–æ-–¥–∞–Ω–Ω—ã—Ö –ø–æ —Å–∏–º–≤–æ–ª—É"""
        base_prices = {
            'SBER': 200, 'GAZP': 150, 'LKOH': 6000, 'NVTK': 1200,
            'ROSN': 400, 'TATN': 3000, 'MGNT': 800, 'MTSS': 300,
            'PIKK': 100, 'IRAO': 50, 'SGZH': 25
        }
        
        base_price = base_prices.get(symbol, 100)
        change = np.random.uniform(-0.05, 0.05)  # ¬±5% –∏–∑–º–µ–Ω–µ–Ω–∏–µ
        current_price = base_price * (1 + change)
        
        return {
            'symbol': symbol,
            'price': current_price,
            'change': change * 100,
            'volume': np.random.randint(1000000, 10000000),
            'timestamp': datetime.now().isoformat()
        }
    
    async def save_real_time_data(self, data: Dict[str, Any], summary: Dict[str, Any]):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏"""
        try:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Ü–µ–Ω—ã
            last_prices_file = os.path.join(self.data_dir, 'real_time', 'last_prices.json')
            with open(last_prices_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–≤–æ–¥–∫—É
            summary_file = os.path.join(self.data_dir, 'real_time', 'data_summary.json')
            with open(summary_file, 'w', encoding='utf-8') as f:
                json.dump(summary, f, ensure_ascii=False, indent=2)
            
            logger.debug("üíæ –î–∞–Ω–Ω—ã–µ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏: {e}")
    
    async def update_historical_data(self):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö"""
        logger.info("üìà –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö...")
        
        try:
            for symbol in self.symbols:
                # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –¥–∞—Ç—É –∏–∑ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ —Ñ–∞–π–ª–∞
                last_date = await self.get_last_date_from_file(symbol)
                
                if last_date:
                    # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Å –ø–æ—Å–ª–µ–¥–Ω–µ–π –¥–∞—Ç—ã
                    historical_data = await self.get_historical_data_from_date(symbol, last_date)
                    
                    if historical_data:
                        # –î–æ–ø–∏—Å—ã–≤–∞–µ–º –≤ —Ñ–∞–π–ª 3-–ª–µ—Ç–Ω–∏—Ö –¥–∞–Ω–Ω—ã—Ö
                        await self.append_to_3year_file(symbol, historical_data)
                        logger.info(f"üìä –û–±–Ω–æ–≤–ª–µ–Ω—ã –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è {symbol}: {len(historical_data)} –∑–∞–ø–∏—Å–µ–π")
                    else:
                        logger.debug(f"‚ÑπÔ∏è –ù–µ—Ç –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {symbol}")
                else:
                    logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω—é—é –¥–∞—Ç—É –¥–ª—è {symbol}")
            
            logger.info("‚úÖ –ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –æ–±–Ω–æ–≤–ª–µ–Ω—ã")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö: {e}")
    
    async def get_last_date_from_file(self, symbol: str) -> Optional[datetime]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–Ω–µ–π –¥–∞—Ç—ã –∏–∑ —Ñ–∞–π–ª–∞ 3-–ª–µ—Ç–Ω–∏—Ö –¥–∞–Ω–Ω—ã—Ö"""
        try:
            file_path = os.path.join(self.data_dir, '3year_minute_data', f'{symbol}_3year_minute.csv')
            
            if not os.path.exists(file_path):
                logger.warning(f"‚ö†Ô∏è –§–∞–π–ª {file_path} –Ω–µ –Ω–∞–π–¥–µ–Ω")
                return None
            
            # –ß–∏—Ç–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Å—Ç—Ä–æ–∫—É —Ñ–∞–π–ª–∞
            with open(file_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
            
            if len(lines) < 2:  # –ú–µ–Ω—å—à–µ –∑–∞–≥–æ–ª–æ–≤–∫–∞ + 1 —Å—Ç—Ä–æ–∫–∞ –¥–∞–Ω–Ω—ã—Ö
                logger.warning(f"‚ö†Ô∏è –§–∞–π–ª {file_path} –ø—É—Å—Ç–æ–π –∏–ª–∏ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–ª—å–∫–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫")
                return None
            
            # –ü–∞—Ä—Å–∏–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Å—Ç—Ä–æ–∫—É –¥–∞–Ω–Ω—ã—Ö
            last_line = lines[-1].strip()
            if not last_line:
                # –ï—Å–ª–∏ –ø–æ—Å–ª–µ–¥–Ω—è—è —Å—Ç—Ä–æ–∫–∞ –ø—É—Å—Ç–∞—è, –±–µ—Ä–µ–º –ø—Ä–µ–¥–ø–æ—Å–ª–µ–¥–Ω—é—é
                if len(lines) >= 3:
                    last_line = lines[-2].strip()
                else:
                    return None
            
            # –†–∞–∑–±–∏—Ä–∞–µ–º CSV —Å—Ç—Ä–æ–∫—É
            parts = last_line.split(',')
            if len(parts) >= 8:  # open,close,high,low,value,volume,begin,end,symbol
                begin_time_str = parts[6]  # begin
                # –ü–∞—Ä—Å–∏–º –¥–∞—Ç—É –∏ –≤—Ä–µ–º—è
                last_date = datetime.strptime(begin_time_str, '%Y-%m-%d %H:%M:%S')
                logger.debug(f"üìÖ –ü–æ—Å–ª–µ–¥–Ω—è—è –¥–∞—Ç–∞ –¥–ª—è {symbol}: {last_date}")
                return last_date
            else:
                logger.error(f"‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç —Å—Ç—Ä–æ–∫–∏ –≤ —Ñ–∞–π–ª–µ {file_path}: {last_line}")
                return None
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –ø–æ—Å–ª–µ–¥–Ω–µ–π –¥–∞—Ç—ã –¥–ª—è {symbol}: {e}")
            return None
    
    async def get_historical_data_from_date(self, symbol: str, from_date: datetime) -> Optional[List[Dict]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö —Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–π –¥–∞—Ç—ã"""
        try:
            current_time = datetime.now()
            if from_date >= current_time:
                logger.debug(f"‚ÑπÔ∏è –î–∞–Ω–Ω—ã–µ –¥–ª—è {symbol} —É–∂–µ –∞–∫—Ç—É–∞–ª—å–Ω—ã")
                return None
            
            if not self.tbank_token:
                logger.warning(f"‚ö†Ô∏è TBANK_TOKEN –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–µ–º–æ-–¥–∞–Ω–Ω—ã–µ –¥–ª—è {symbol}")
                return await self.get_demo_historical_data(symbol, from_date, current_time)
            
            # –ó–¥–µ—Å—å –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Ä–µ–∞–ª—å–Ω—ã–π API –≤—ã–∑–æ–≤ –∫ T-Bank
            # –ü–æ–∫–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–µ–º–æ-–¥–∞–Ω–Ω—ã–µ
            return await self.get_demo_historical_data(symbol, from_date, current_time)
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {symbol}: {e}")
            return None
    
    async def get_demo_historical_data(self, symbol: str, from_date: datetime, current_time: datetime) -> List[Dict]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–µ–º–æ-–∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö"""
        data = []
        current_minute = from_date + timedelta(minutes=1)  # –ù–∞—á–∏–Ω–∞–µ–º —Å–æ —Å–ª–µ–¥—É—é—â–µ–π –º–∏–Ω—É—Ç—ã
        
        # –ë–∞–∑–æ–≤—ã–µ —Ü–µ–Ω—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤
        base_prices = {
            'SBER': 200, 'GAZP': 150, 'LKOH': 6000, 'NVTK': 1200,
            'ROSN': 400, 'TATN': 3000, 'MGNT': 800, 'MTSS': 300,
            'PIKK': 100, 'IRAO': 50, 'SGZH': 25
        }
        
        base_price = base_prices.get(symbol, 100)
        current_price = base_price
        
        while current_minute <= current_time:
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ü–µ–Ω—É —Å –Ω–µ–±–æ–ª—å—à–∏–º —Å–ª—É—á–∞–π–Ω—ã–º –∏–∑–º–µ–Ω–µ–Ω–∏–µ–º
            price_change = np.random.uniform(-0.01, 0.01)  # ¬±1% –∏–∑–º–µ–Ω–µ–Ω–∏–µ
            current_price = current_price * (1 + price_change)
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º OHLC –¥–∞–Ω–Ω—ã–µ
            open_price = current_price
            high_price = current_price * (1 + abs(np.random.uniform(0, 0.005)))
            low_price = current_price * (1 - abs(np.random.uniform(0, 0.005)))
            close_price = current_price * (1 + np.random.uniform(-0.002, 0.002))
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ–±—ä–µ–º
            volume = np.random.randint(10000, 100000)
            value = close_price * volume
            
            # –°–æ–∑–¥–∞–µ–º –∑–∞–ø–∏—Å—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ CSV
            data.append({
                'open': round(open_price, 2),
                'close': round(close_price, 2),
                'high': round(high_price, 2),
                'low': round(low_price, 2),
                'value': round(value, 2),
                'volume': volume,
                'begin': current_minute.strftime('%Y-%m-%d %H:%M:%S'),
                'end': (current_minute + timedelta(seconds=59)).strftime('%Y-%m-%d %H:%M:%S'),
                'symbol': symbol
            })
            
            current_minute += timedelta(minutes=1)
        
        logger.debug(f"üìä –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(data)} –∑–∞–ø–∏—Å–µ–π –¥–ª—è {symbol} —Å {from_date}")
        return data
    
    async def append_to_3year_file(self, symbol: str, data: List[Dict]):
        """–î–æ–ø–∏—Å—ã–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ —Ñ–∞–π–ª 3-–ª–µ—Ç–Ω–∏—Ö –¥–∞–Ω–Ω—ã—Ö"""
        try:
            file_path = os.path.join(self.data_dir, '3year_minute_data', f'{symbol}_3year_minute.csv')
            
            # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
            os.makedirs(os.path.dirname(file_path), exist_ok=True)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —Ñ–∞–π–ª
            file_exists = os.path.exists(file_path)
            
            # –û—Ç–∫—Ä—ã–≤–∞–µ–º —Ñ–∞–π–ª –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è
            with open(file_path, 'a', encoding='utf-8', newline='') as f:
                # –ï—Å–ª–∏ —Ñ–∞–π–ª –Ω–æ–≤—ã–π, –¥–æ–±–∞–≤–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
                if not file_exists:
                    f.write('open,close,high,low,value,volume,begin,end,symbol\n')
                
                # –î–æ–±–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ
                for record in data:
                    line = f"{record['open']},{record['close']},{record['high']},{record['low']},{record['value']},{record['volume']},{record['begin']},{record['end']},{record['symbol']}\n"
                    f.write(line)
            
            logger.debug(f"üíæ –î–æ–±–∞–≤–ª–µ–Ω–æ {len(data)} –∑–∞–ø–∏—Å–µ–π –≤ {file_path}")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {symbol}: {e}")
    
    async def get_historical_data(self, symbol: str, days: int = 1) -> Optional[List[Dict]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö (—É—Å—Ç–∞—Ä–µ–≤—à–∏–π –º–µ—Ç–æ–¥)"""
        # –≠—Ç–æ—Ç –º–µ—Ç–æ–¥ –æ—Å—Ç–∞–≤–ª–µ–Ω –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        return await self.get_historical_data_from_date(symbol, datetime.now() - timedelta(days=days))
    
    async def append_historical_data(self, symbol: str, data: List[Dict]):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º (—É—Å—Ç–∞—Ä–µ–≤—à–∏–π –º–µ—Ç–æ–¥)"""
        # –ü–µ—Ä–µ–Ω–∞–ø—Ä–∞–≤–ª—è–µ–º –Ω–∞ –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ –¥–ª—è 3-–ª–µ—Ç–Ω–∏—Ö —Ñ–∞–π–ª–æ–≤
        await self.append_to_3year_file(symbol, data)
    
    async def check_data_status(self) -> Dict[str, Any]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤—Å–µ—Ö —Å–∏–º–≤–æ–ª–æ–≤"""
        status = {
            'symbols': {},
            'total_symbols': len(self.symbols),
            'files_found': 0,
            'last_update': None,
            'oldest_data': None,
            'newest_data': None
        }
        
        for symbol in self.symbols:
            try:
                file_path = os.path.join(self.data_dir, '3year_minute_data', f'{symbol}_3year_minute.csv')
                
                if os.path.exists(file_path):
                    # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–π–ª–µ
                    file_size = os.path.getsize(file_path)
                    last_modified = datetime.fromtimestamp(os.path.getmtime(file_path))
                    
                    # –ü–æ–ª—É—á–∞–µ–º –ø–µ—Ä–≤—É—é –∏ –ø–æ—Å–ª–µ–¥–Ω—é—é –¥–∞—Ç—ã
                    first_date, last_date = await self.get_file_date_range(symbol)
                    
                    status['symbols'][symbol] = {
                        'file_exists': True,
                        'file_size_mb': round(file_size / (1024 * 1024), 2),
                        'last_modified': last_modified.isoformat(),
                        'first_date': first_date.isoformat() if first_date else None,
                        'last_date': last_date.isoformat() if last_date else None,
                        'records_count': await self.get_file_records_count(symbol)
                    }
                    
                    status['files_found'] += 1
                    
                    # –û–±–Ω–æ–≤–ª—è–µ–º –æ–±—â–∏–µ –¥–∞—Ç—ã
                    if first_date and (not status['oldest_data'] or first_date < status['oldest_data']):
                        status['oldest_data'] = first_date
                    
                    if last_date and (not status['newest_data'] or last_date > status['newest_data']):
                        status['newest_data'] = last_date
                        status['last_update'] = last_date
                        
                else:
                    status['symbols'][symbol] = {
                        'file_exists': False,
                        'file_size_mb': 0,
                        'last_modified': None,
                        'first_date': None,
                        'last_date': None,
                        'records_count': 0
                    }
                    
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å—Ç–∞—Ç—É—Å–∞ –¥–ª—è {symbol}: {e}")
                status['symbols'][symbol] = {
                    'file_exists': False,
                    'error': str(e)
                }
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –¥–∞—Ç—ã –≤ —Å—Ç—Ä–æ–∫–∏
        if status['oldest_data']:
            status['oldest_data'] = status['oldest_data'].isoformat()
        if status['newest_data']:
            status['newest_data'] = status['newest_data'].isoformat()
        if status['last_update']:
            status['last_update'] = status['last_update'].isoformat()
        
        return status
    
    async def get_file_date_range(self, symbol: str) -> Tuple[Optional[datetime], Optional[datetime]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ –¥–∞—Ç –∏–∑ —Ñ–∞–π–ª–∞"""
        try:
            file_path = os.path.join(self.data_dir, '3year_minute_data', f'{symbol}_3year_minute.csv')
            
            if not os.path.exists(file_path):
                return None, None
            
            with open(file_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
            
            if len(lines) < 2:
                return None, None
            
            # –ü–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ –¥–∞–Ω–Ω—ã—Ö (–ø–æ—Å–ª–µ –∑–∞–≥–æ–ª–æ–≤–∫–∞)
            first_line = lines[1].strip()
            first_parts = first_line.split(',')
            if len(first_parts) >= 7:
                first_date = datetime.strptime(first_parts[6], '%Y-%m-%d %H:%M:%S')
            else:
                first_date = None
            
            # –ü–æ—Å–ª–µ–¥–Ω—è—è —Å—Ç—Ä–æ–∫–∞ –¥–∞–Ω–Ω—ã—Ö
            last_line = lines[-1].strip()
            if not last_line:
                last_line = lines[-2].strip()
            
            last_parts = last_line.split(',')
            if len(last_parts) >= 7:
                last_date = datetime.strptime(last_parts[6], '%Y-%m-%d %H:%M:%S')
            else:
                last_date = None
            
            return first_date, last_date
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∏–∞–ø–∞–∑–æ–Ω–∞ –¥–∞—Ç –¥–ª—è {symbol}: {e}")
            return None, None
    
    async def get_file_records_count(self, symbol: str) -> int:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∑–∞–ø–∏—Å–µ–π –≤ —Ñ–∞–π–ª–µ"""
        try:
            file_path = os.path.join(self.data_dir, '3year_minute_data', f'{symbol}_3year_minute.csv')
            
            if not os.path.exists(file_path):
                return 0
            
            with open(file_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
            
            # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –º–∏–Ω—É—Å –∑–∞–≥–æ–ª–æ–≤–æ–∫
            return max(0, len(lines) - 1)
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥—Å—á–µ—Ç–∞ –∑–∞–ø–∏—Å–µ–π –¥–ª—è {symbol}: {e}")
            return 0

class NewsDataUpdater:
    """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π"""
    
    def __init__(self):
        self.news_manager = NewsDataManager()
        self.news_analyzer = None
        
        try:
            self.news_analyzer = RussianNewsAnalyzer("russian_news_config.json")
            logger.info("‚úÖ –û–±–Ω–æ–≤–ª—è—Ç–µ–ª—å –Ω–æ–≤–æ—Å—Ç–µ–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ –Ω–æ–≤–æ—Å—Ç–µ–π: {e}")
    
    async def update_news_data(self):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π"""
        logger.info("üì∞ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π...")
        
        try:
            # –ü–æ–ª—É—á–∞–µ–º –Ω–æ–≤—ã–µ –Ω–æ–≤–æ—Å—Ç–∏
            new_news = await self.fetch_latest_news()
            
            if new_news:
                # –î–æ–±–∞–≤–ª—è–µ–º –∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º –¥–∞–Ω–Ω—ã–º
                await self.append_news_data(new_news)
                logger.info(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ {len(new_news)} –Ω–æ–≤—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π")
            else:
                logger.info("‚ÑπÔ∏è –ù–æ–≤—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π: {e}")
    
    async def fetch_latest_news(self) -> List[Dict[str, Any]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π"""
        new_news = []
        
        if not self.news_analyzer:
            logger.warning("‚ö†Ô∏è –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –Ω–æ–≤–æ—Å—Ç–µ–π –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            return new_news
        
        try:
            # –ü–æ–ª—É—á–∞–µ–º –Ω–æ–≤–æ—Å—Ç–∏ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 24 —á–∞—Å–∞
            end_date = datetime.now()
            start_date = end_date - timedelta(hours=24)
            
            # –ó–¥–µ—Å—å –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Ä–µ–∞–ª—å–Ω—ã–π API –≤—ã–∑–æ–≤
            # –î–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –Ω–æ–≤–æ—Å—Ç–µ–π
            symbols = ['SBER', 'GAZP', 'LKOH', 'NVTK', 'ROSN', 'TATN']
            
            for symbol in symbols:
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º 1-3 –Ω–æ–≤–æ—Å—Ç–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–∏–º–≤–æ–ª–∞
                num_news = np.random.randint(1, 4)
                
                for _ in range(num_news):
                    news_item = await self.generate_sample_news(symbol, start_date, end_date)
                    new_news.append(news_item)
            
            logger.debug(f"üì∞ –ü–æ–ª—É—á–µ–Ω–æ {len(new_news)} –Ω–æ–≤—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π: {e}")
        
        return new_news
    
    async def generate_sample_news(self, symbol: str, start_date: datetime, end_date: datetime) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–∏–º–µ—Ä–∞ –Ω–æ–≤–æ—Å—Ç–∏"""
        
        news_templates = [
            {
                'title': f'{symbol}: –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π',
                'content': f'–ö–æ–º–ø–∞–Ω–∏—è {symbol} –æ–ø—É–±–ª–∏–∫–æ–≤–∞–ª–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏.',
                'sentiment_score': 0.3,
                'confidence': 0.6,
                'impact': 'medium'
            },
            {
                'title': f'{symbol}: –¢–æ—Ä–≥–æ–≤—ã–µ —Å–µ—Å—Å–∏–∏',
                'content': f'–¢–æ—Ä–≥–∏ {symbol} –ø—Ä–æ—à–ª–∏ –≤ –æ–±—ã—á–Ω–æ–º —Ä–µ–∂–∏–º–µ.',
                'sentiment_score': 0.1,
                'confidence': 0.4,
                'impact': 'low'
            },
            {
                'title': f'{symbol}: –ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è',
                'content': f'–ö–æ–º–ø–∞–Ω–∏—è {symbol} –ø—Ä–æ–≤–µ–ª–∞ –ø–ª–∞–Ω–æ–≤—ã–µ –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã–µ –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è.',
                'sentiment_score': 0.0,
                'confidence': 0.3,
                'impact': 'low'
            }
        ]
        
        template = np.random.choice(news_templates)
        publish_time = start_date + timedelta(
            seconds=np.random.randint(0, int((end_date - start_date).total_seconds()))
        )
        
        return {
            'title': template['title'],
            'content': template['content'],
            'published_at': publish_time,
            'source': 'Real-time News',
            'symbol': symbol,
            'sentiment_score': template['sentiment_score'],
            'confidence': template['confidence'],
            'impact': template['impact'],
            'category': self._categorize_news(template['sentiment_score']),
            'id': f"{symbol}_{publish_time.strftime('%Y%m%d_%H%M%S')}_{np.random.randint(1000, 9999)}"
        }
    
    def _categorize_news(self, sentiment_score: float) -> str:
        """–ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π –ø–æ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—é"""
        if sentiment_score > 0.5:
            return 'very_positive'
        elif sentiment_score > 0.2:
            return 'positive'
        elif sentiment_score > -0.2:
            return 'neutral'
        elif sentiment_score > -0.5:
            return 'negative'
        else:
            return 'very_negative'
    
    async def append_news_data(self, new_news: List[Dict[str, Any]]):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º –¥–∞–Ω–Ω—ã–º"""
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ
            existing_data = self.news_manager.load_news_data()
            
            if not existing_data:
                existing_data = {}
            
            # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –Ω–æ–≤—ã–µ –Ω–æ–≤–æ—Å—Ç–∏ –ø–æ —Å–∏–º–≤–æ–ª–∞–º
            for news_item in new_news:
                symbol = news_item['symbol']
                
                if symbol not in existing_data:
                    existing_data[symbol] = []
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ—Ç –ª–∏ —É–∂–µ —Ç–∞–∫–æ–π –Ω–æ–≤–æ—Å—Ç–∏
                news_id = news_item.get('id', '')
                if not any(n.get('id') == news_id for n in existing_data[symbol]):
                    existing_data[symbol].append(news_item)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            self.news_manager.save_news_data(existing_data)
            
            logger.debug(f"üíæ –î–æ–±–∞–≤–ª–µ–Ω–æ {len(new_news)} –Ω–æ–≤–æ—Å—Ç–µ–π –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π: {e}")

class ModelRetrainer:
    """–ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π"""
    
    def __init__(self):
        self.models_dir = "trained_models"
        self.retrain_threshold = 0.1  # 10% –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        
        logger.info("‚úÖ –ü–µ—Ä–µ–æ–±—É—á–∞—Ç–µ–ª—å –º–æ–¥–µ–ª–µ–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    
    async def check_retrain_necessity(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            new_data_ratio = await self.calculate_new_data_ratio()
            
            if new_data_ratio >= self.retrain_threshold:
                logger.info(f"üîÑ –ù–µ–æ–±—Ö–æ–¥–∏–º–æ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ: {new_data_ratio:.1%} –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
                return True
            else:
                logger.debug(f"‚ÑπÔ∏è –ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è: {new_data_ratio:.1%} –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
                return False
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è: {e}")
            return False
    
    async def calculate_new_data_ratio(self) -> float:
        """–†–∞—Å—á–µ—Ç –¥–æ–ª–∏ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        # –ó–¥–µ—Å—å –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ª–æ–≥–∏–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ –¥–æ–ª–∏ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        # –î–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–ª—É—á–∞–π–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
        return np.random.uniform(0.05, 0.15)
    
    async def retrain_models(self):
        """–ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π"""
        logger.info("üîÑ –ó–∞–ø—É—Å–∫ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π...")
        
        try:
            # –ó–¥–µ—Å—å –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ª–æ–≥–∏–∫–∞ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è
            # –ó–∞–ø—É—Å–∫–∞–µ–º —Å–∫—Ä–∏–ø—Ç –æ–±—É—á–µ–Ω–∏—è
            import subprocess
            
            result = subprocess.run([
                sys.executable, 'model_training_script.py'
            ], capture_output=True, text=True)
            
            if result.returncode == 0:
                logger.info("‚úÖ –ú–æ–¥–µ–ª–∏ —É—Å–ø–µ—à–Ω–æ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω—ã")
            else:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π: {result.stderr}")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π: {e}")

class DataUpdateService:
    """–û—Å–Ω–æ–≤–Ω–æ–π —Å–µ—Ä–≤–∏—Å –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö"""
    
    def __init__(self, config_file: str = "data_update_config.json"):
        self.config_file = config_file
        self.config = {}
        self.market_updater = MarketDataUpdater()
        self.news_updater = NewsDataUpdater()
        self.model_retrainer = ModelRetrainer()
        self.running = False
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
        self.load_configuration()
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è
        self.setup_schedule()
        
        logger.info("‚úÖ –°–µ—Ä–≤–∏—Å –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    
    def load_configuration(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        # –ó–∞–≥—Ä—É–∂–∞–µ–º .env —Ñ–∞–π–ª
        env_paths = ['.env', 'config/.env', 'config/environments/.env']
        for path in env_paths:
            if os.path.exists(path):
                load_env_file(path)
                break
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —Å–µ—Ä–≤–∏—Å–∞
        if os.path.exists(self.config_file):
            with open(self.config_file, 'r', encoding='utf-8') as f:
                self.config = json.load(f)
        else:
            self.create_default_config()
    
    def create_default_config(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é"""
        self.config = {
            "service": {
                "name": "Data Update Service",
                "version": "1.0.0",
                "description": "–°–µ—Ä–≤–∏—Å –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç–æ—Ä–≥–æ–≤—ã—Ö —Ä–æ–±–æ—Ç–æ–≤"
            },
            "schedule": {
                "market_data_interval": 60,  # 1 –º–∏–Ω—É—Ç–∞
                "news_data_interval": 300,   # 5 –º–∏–Ω—É—Ç
                "historical_data_interval": 3600,  # 1 —á–∞—Å
                "model_retrain_interval": 86400,   # 24 —á–∞—Å–∞
                "retrain_check_interval": 3600     # 1 —á–∞—Å
            },
            "data": {
                "storage_path": "data/",
                "backup_enabled": True,
                "max_storage_size_gb": 10
            },
            "monitoring": {
                "log_level": "INFO",
                "performance_metrics": True,
                "alerts_enabled": True
            }
        }
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
        with open(self.config_file, 'w', encoding='utf-8') as f:
            json.dump(self.config, f, ensure_ascii=False, indent=2)
    
    def setup_schedule(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π"""
        schedule_config = self.config.get('schedule', {})
        
        # –†—ã–Ω–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∫–∞–∂–¥—É—é –º–∏–Ω—É—Ç—É
        market_interval = schedule_config.get('market_data_interval', 60)
        schedule.every(market_interval).seconds.do(self.run_market_data_update)
        
        # –ù–æ–≤–æ—Å—Ç–∏ –∫–∞–∂–¥—ã–µ 5 –º–∏–Ω—É—Ç
        news_interval = schedule_config.get('news_data_interval', 300)
        schedule.every(news_interval).seconds.do(self.run_news_data_update)
        
        # –ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –∫–∞–∂–¥—ã–π —á–∞—Å
        historical_interval = schedule_config.get('historical_data_interval', 3600)
        schedule.every(historical_interval).seconds.do(self.run_historical_data_update)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è –∫–∞–∂–¥—ã–π —á–∞—Å
        retrain_check_interval = schedule_config.get('retrain_check_interval', 3600)
        schedule.every(retrain_check_interval).seconds.do(self.run_retrain_check)
        
        logger.info("‚è∞ –†–∞—Å–ø–∏—Å–∞–Ω–∏–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π –Ω–∞—Å—Ç—Ä–æ–µ–Ω–æ")
    
    def run_market_data_update(self):
        """–ó–∞–ø—É—Å–∫ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Ä—ã–Ω–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        asyncio.run(self.market_updater.update_real_time_data())
    
    def run_news_data_update(self):
        """–ó–∞–ø—É—Å–∫ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π"""
        asyncio.run(self.news_updater.update_news_data())
    
    def run_historical_data_update(self):
        """–ó–∞–ø—É—Å–∫ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö"""
        asyncio.run(self.market_updater.update_historical_data())
    
    def run_retrain_check(self):
        """–ó–∞–ø—É—Å–∫ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è"""
        async def check_and_retrain():
            if await self.model_retrainer.check_retrain_necessity():
                await self.model_retrainer.retrain_models()
        
        asyncio.run(check_and_retrain())
    
    def start_service(self):
        """–ó–∞–ø—É—Å–∫ —Å–µ—Ä–≤–∏—Å–∞"""
        logger.info("üöÄ –ó–∞–ø—É—Å–∫ —Å–µ—Ä–≤–∏—Å–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö...")
        
        self.running = True
        
        try:
            while self.running:
                schedule.run_pending()
                time.sleep(1)
        except KeyboardInterrupt:
            logger.info("üõë –°–µ—Ä–≤–∏—Å –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ —Å–µ—Ä–≤–∏—Å–µ: {e}")
        finally:
            self.cleanup()
    
    def cleanup(self):
        """–û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤"""
        logger.info("üßπ –û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤ —Å–µ—Ä–≤–∏—Å–∞...")
        
        if self.news_updater.news_analyzer:
            asyncio.run(self.news_updater.news_analyzer.close())
        
        logger.info("‚úÖ –û—á–∏—Å—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
    
    def stop_service(self):
        """–û—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å–µ—Ä–≤–∏—Å–∞"""
        logger.info("üõë –û—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å–µ—Ä–≤–∏—Å–∞...")
        self.running = False

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    import argparse
    
    parser = argparse.ArgumentParser(description='–°–µ—Ä–≤–∏—Å –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö')
    parser.add_argument('--config', '-c', default='data_update_config.json',
                       help='–§–∞–π–ª –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏')
    parser.add_argument('--once', action='store_true',
                       help='–í—ã–ø–æ–ª–Ω–∏—Ç—å –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –æ–¥–∏–Ω —Ä–∞–∑')
    parser.add_argument('--market-only', action='store_true',
                       help='–û–±–Ω–æ–≤–∏—Ç—å —Ç–æ–ª—å–∫–æ —Ä—ã–Ω–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ')
    parser.add_argument('--news-only', action='store_true',
                       help='–û–±–Ω–æ–≤–∏—Ç—å —Ç–æ–ª—å–∫–æ –Ω–æ–≤–æ—Å—Ç–∏')
    parser.add_argument('--status', action='store_true',
                       help='–ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç—É—Å –¥–∞–Ω–Ω—ã—Ö')
    
    args = parser.parse_args()
    
    # –°–æ–∑–¥–∞–µ–º —Å–µ—Ä–≤–∏—Å
    service = DataUpdateService(args.config)
    
    if args.status:
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç—É—Å –¥–∞–Ω–Ω—ã—Ö
        async def show_status():
            status = await service.market_updater.check_data_status()
            
            print("\nüìä –°–¢–ê–¢–£–° –î–ê–ù–ù–´–• 3-–õ–ï–¢–ù–ò–• –§–ê–ô–õ–û–í:")
            print("=" * 80)
            print(f"üìÅ –í—Å–µ–≥–æ —Å–∏–º–≤–æ–ª–æ–≤: {status['total_symbols']}")
            print(f"üìÑ –§–∞–π–ª–æ–≤ –Ω–∞–π–¥–µ–Ω–æ: {status['files_found']}")
            print(f"üìÖ –°–∞–º–∞—è —Å—Ç–∞—Ä–∞—è –¥–∞—Ç–∞: {status['oldest_data']}")
            print(f"üìÖ –°–∞–º–∞—è –Ω–æ–≤–∞—è –¥–∞—Ç–∞: {status['newest_data']}")
            print(f"üïí –ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ: {status['last_update']}")
            print()
            
            print("üìà –î–ï–¢–ê–õ–ò –ü–û –°–ò–ú–í–û–õ–ê–ú:")
            print("-" * 80)
            
            for symbol, info in status['symbols'].items():
                if info.get('file_exists'):
                    print(f"\n{symbol}:")
                    print(f"  üìÑ –§–∞–π–ª: {symbol}_3year_minute.csv")
                    print(f"  üìä –†–∞–∑–º–µ—Ä: {info['file_size_mb']} MB")
                    print(f"  üìù –ó–∞–ø–∏—Å–µ–π: {info['records_count']:,}")
                    print(f"  üìÖ –ü–µ—Ä–≤–∞—è –¥–∞—Ç–∞: {info['first_date']}")
                    print(f"  üìÖ –ü–æ—Å–ª–µ–¥–Ω—è—è –¥–∞—Ç–∞: {info['last_date']}")
                    print(f"  üïí –ò–∑–º–µ–Ω–µ–Ω: {info['last_modified']}")
                else:
                    print(f"\n{symbol}: ‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")
                    if 'error' in info:
                        print(f"  ‚ùå –û—à–∏–±–∫–∞: {info['error']}")
        
        asyncio.run(show_status())
        
    elif args.once:
        # –í—ã–ø–æ–ª–Ω—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –æ–¥–∏–Ω —Ä–∞–∑
        logger.info("üîÑ –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Ä–∞–∑–æ–≤–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è...")
        
        if args.market_only:
            service.run_market_data_update()
        elif args.news_only:
            service.run_news_data_update()
        else:
            service.run_market_data_update()
            service.run_news_data_update()
            service.run_historical_data_update()
        
        logger.info("‚úÖ –†–∞–∑–æ–≤–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")
    else:
        # –ó–∞–ø—É—Å–∫–∞–µ–º —Å–µ—Ä–≤–∏—Å
        service.start_service()

if __name__ == "__main__":
    main()
